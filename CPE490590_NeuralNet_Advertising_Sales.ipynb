{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for Prediction using TensorFlow 2.0 (Objected-Oriented)\n",
    "## CPE 490 590 \n",
    "### Author: Rahul Bhadani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Serif'\n",
    "plt.rcParams['font.size'] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 22:13:22.378783: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 22:13:22.386073: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 22:13:22.472301: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 22:13:22.472353: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 22:13:22.474750: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 22:13:22.488390: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 22:13:22.489310: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 22:13:24.176595: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>38.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>94.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>177.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>283.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>66.2</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>232.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  Radio  Newspaper  Sales\n",
       "1    230.1   37.8       69.2   22.1\n",
       "2     44.5   39.3       45.1   10.4\n",
       "3     17.2   45.9       69.3    9.3\n",
       "4    151.5   41.3       58.5   18.5\n",
       "5    180.8   10.8       58.4   12.9\n",
       "..     ...    ...        ...    ...\n",
       "196   38.2    3.7       13.8    7.6\n",
       "197   94.2    4.9        8.1    9.7\n",
       "198  177.0    9.3        6.4   12.8\n",
       "199  283.6   42.0       66.2   25.5\n",
       "200  232.1    8.6        8.7   13.4\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset/Advertising/Advertising.csv', index_col = 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, response variable is `Sales` that we want to predict based on sales of `TV`, `Radio`, `Newspaper`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['Sales']]  # Response Variable\n",
    "x = df.drop('Sales', axis=1) # Feature Matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Dataset into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(x, y, test_size = 1/3, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Class for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 22:14:40.709545: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "class NeuralNetwork(Model):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = Dense(4, activation='relu')\n",
    "        self.layer2 = Dense(2, activation='relu')\n",
    "        self.layer3 = Dense(3, activation='relu')\n",
    "        self.output_layer = Dense(1)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "neuralnet_model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 [==============================] - 2s 113ms/step - loss: 325.1198 - val_loss: 641.1539\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 311.1218 - val_loss: 602.9796\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 297.1518 - val_loss: 569.7262\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 286.6675 - val_loss: 537.1312\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 276.4860 - val_loss: 507.8944\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 265.5916 - val_loss: 483.2943\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 255.9152 - val_loss: 460.6536\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 245.2867 - val_loss: 436.5101\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 230.4306 - val_loss: 411.5289\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 209.5725 - val_loss: 385.6936\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 188.3069 - val_loss: 355.7214\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 162.8044 - val_loss: 326.9783\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 142.0489 - val_loss: 294.9816\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 120.5147 - val_loss: 266.5414\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 106.2293 - val_loss: 240.9525\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 93.8089 - val_loss: 217.8472\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 81.7747 - val_loss: 196.0900\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 70.2472 - val_loss: 175.9354\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 61.9176 - val_loss: 159.2957\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 54.4510 - val_loss: 146.1879\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 49.1544 - val_loss: 133.7324\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 43.8928 - val_loss: 123.5704\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 39.9497 - val_loss: 113.1502\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 36.3939 - val_loss: 104.6929\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 33.6094 - val_loss: 96.6280\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 30.9701 - val_loss: 90.3560\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 29.2862 - val_loss: 85.1243\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 27.4732 - val_loss: 80.6458\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 25.9519 - val_loss: 75.5413\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 24.6872 - val_loss: 71.4058\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 23.5825 - val_loss: 67.5554\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 22.3709 - val_loss: 64.3331\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 21.3726 - val_loss: 61.6561\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 20.6980 - val_loss: 59.1848\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 20.0988 - val_loss: 56.9432\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 19.3745 - val_loss: 55.1352\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 18.8339 - val_loss: 53.2574\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 18.3057 - val_loss: 51.6213\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 17.8943 - val_loss: 49.9834\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 17.4031 - val_loss: 48.6025\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 16.9662 - val_loss: 47.2689\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 16.5462 - val_loss: 45.2251\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 16.0271 - val_loss: 43.6504\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 15.6114 - val_loss: 42.2465\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 15.2465 - val_loss: 40.3610\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 14.7299 - val_loss: 38.9230\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 14.3262 - val_loss: 37.7784\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 14.0298 - val_loss: 36.7814\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 13.7456 - val_loss: 35.7250\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 13.4665 - val_loss: 34.4191\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 13.1376 - val_loss: 33.5061\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.8987 - val_loss: 32.7863\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 12.6458 - val_loss: 32.0345\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 12.4355 - val_loss: 31.4396\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 12.2784 - val_loss: 30.8629\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 12.1096 - val_loss: 30.2772\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 11.9476 - val_loss: 29.4170\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 11.7131 - val_loss: 28.7824\n",
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 11.5474 - val_loss: 28.2539\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 11.3962 - val_loss: 27.7841\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.2375 - val_loss: 27.3054\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 11.0978 - val_loss: 26.6579\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 10.9444 - val_loss: 26.0350\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 10.8321 - val_loss: 25.3587\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 10.6660 - val_loss: 24.7622\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 10.4993 - val_loss: 24.2047\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 10.3895 - val_loss: 23.2861\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 10.2297 - val_loss: 22.7127\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 10.1087 - val_loss: 22.2308\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.9740 - val_loss: 21.7706\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 9.8331 - val_loss: 21.2748\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 9.7329 - val_loss: 20.7427\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.6348 - val_loss: 20.3440\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.5552 - val_loss: 20.0392\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 9.4699 - val_loss: 19.7817\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 9.3894 - val_loss: 19.5698\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 9.3169 - val_loss: 19.3556\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 9.2456 - val_loss: 19.1775\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 9.1712 - val_loss: 18.9239\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 9.0740 - val_loss: 18.4519\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 8.9966 - val_loss: 17.9992\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.9141 - val_loss: 17.6862\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.8503 - val_loss: 17.4721\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 8.7693 - val_loss: 17.2772\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.7347 - val_loss: 17.1126\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 8.6617 - val_loss: 16.9745\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.5923 - val_loss: 16.7970\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 8.5151 - val_loss: 16.5634\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 8.4704 - val_loss: 16.3418\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 8.3866 - val_loss: 16.1482\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 8.3258 - val_loss: 16.0093\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.2717 - val_loss: 15.8733\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 8.2056 - val_loss: 15.6422\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 8.1492 - val_loss: 15.2414\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 8.0933 - val_loss: 14.9739\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 8.0232 - val_loss: 14.7761\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 7.9597 - val_loss: 14.6479\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.9250 - val_loss: 14.5124\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 7.8781 - val_loss: 14.4229\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.8278 - val_loss: 14.3490\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.7922 - val_loss: 14.2691\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.7554 - val_loss: 14.2413\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.7093 - val_loss: 14.1809\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.6883 - val_loss: 14.0769\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 7.6544 - val_loss: 14.0844\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.6050 - val_loss: 14.0400\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 7.5638 - val_loss: 13.9540\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.5175 - val_loss: 13.8178\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.4988 - val_loss: 13.6858\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.4515 - val_loss: 13.5579\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.4083 - val_loss: 13.3424\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 7.3679 - val_loss: 13.0132\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 7.3312 - val_loss: 12.7856\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 7.2823 - val_loss: 12.7311\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.3005 - val_loss: 12.5633\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.2173 - val_loss: 12.3632\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.2326 - val_loss: 12.3085\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 7.2889 - val_loss: 12.2350\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 7.1497 - val_loss: 12.2497\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 7.0890 - val_loss: 12.2491\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 7.0951 - val_loss: 12.2345\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 7.0690 - val_loss: 12.1332\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 7.0081 - val_loss: 12.0769\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.9755 - val_loss: 11.9724\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 6.9580 - val_loss: 11.9264\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 6.9152 - val_loss: 11.9132\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 6.9012 - val_loss: 11.8990\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.8533 - val_loss: 11.8205\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.8419 - val_loss: 11.8335\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.8144 - val_loss: 11.8093\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 6.7770 - val_loss: 11.7468\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.7623 - val_loss: 11.6564\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.7789 - val_loss: 11.5682\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.7292 - val_loss: 11.4761\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.6794 - val_loss: 11.4870\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.6591 - val_loss: 11.4673\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.6198 - val_loss: 11.2904\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.5751 - val_loss: 11.1717\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 6.5906 - val_loss: 10.9866\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 6.5645 - val_loss: 10.8760\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.4666 - val_loss: 10.8685\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.4845 - val_loss: 10.9418\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.5111 - val_loss: 10.7772\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.4303 - val_loss: 10.5428\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.4127 - val_loss: 10.4745\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.3780 - val_loss: 10.4198\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.3188 - val_loss: 10.3907\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 6.3117 - val_loss: 10.5003\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.4032 - val_loss: 10.5301\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.3015 - val_loss: 10.3798\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.2042 - val_loss: 10.3889\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.1751 - val_loss: 10.4049\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 6.1482 - val_loss: 10.4434\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 6.1170 - val_loss: 10.4516\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 6.0822 - val_loss: 10.4824\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 6.0662 - val_loss: 10.4859\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 6.0888 - val_loss: 10.4853\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 6.0311 - val_loss: 10.3545\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 6.0045 - val_loss: 10.3075\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.9776 - val_loss: 10.2708\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.9339 - val_loss: 10.2636\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 5.9100 - val_loss: 10.2068\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 5.8906 - val_loss: 10.2075\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.8841 - val_loss: 10.2105\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.8384 - val_loss: 10.2137\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.8363 - val_loss: 10.1880\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.7932 - val_loss: 10.0644\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.7458 - val_loss: 9.9795\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.7245 - val_loss: 9.9217\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.6890 - val_loss: 9.8890\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.7041 - val_loss: 9.8571\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.6487 - val_loss: 9.6743\n",
      "Epoch 173/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 5.6034 - val_loss: 9.5525\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 5.5766 - val_loss: 9.3427\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.5697 - val_loss: 9.1985\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.5284 - val_loss: 9.1323\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.4917 - val_loss: 9.1275\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.4911 - val_loss: 9.1138\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.4487 - val_loss: 9.0186\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.4379 - val_loss: 8.9804\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.4180 - val_loss: 8.9269\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 5.3537 - val_loss: 8.9180\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 5.3412 - val_loss: 8.9312\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.3184 - val_loss: 8.8989\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 5.3020 - val_loss: 8.8680\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.2506 - val_loss: 8.9057\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.2254 - val_loss: 8.9088\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 5.2161 - val_loss: 8.8778\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.1838 - val_loss: 8.8329\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.1521 - val_loss: 8.8066\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1281 - val_loss: 8.7845\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.1085 - val_loss: 8.7385\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.0887 - val_loss: 8.6766\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 5.0575 - val_loss: 8.6281\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 5.0299 - val_loss: 8.5675\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 5.0042 - val_loss: 8.5093\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.9781 - val_loss: 8.4166\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.9535 - val_loss: 8.2377\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.9252 - val_loss: 8.1034\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.9029 - val_loss: 8.0212\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.8757 - val_loss: 7.9724\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.8584 - val_loss: 7.9684\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.8500 - val_loss: 7.9892\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.8400 - val_loss: 8.0153\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.8103 - val_loss: 8.0152\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.7599 - val_loss: 8.0041\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 4.7360 - val_loss: 7.9831\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.7186 - val_loss: 7.9175\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.6888 - val_loss: 7.8713\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 4.6794 - val_loss: 7.8495\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 4.6539 - val_loss: 7.7682\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 4.6193 - val_loss: 7.7203\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.6074 - val_loss: 7.7158\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.5926 - val_loss: 7.6909\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.5662 - val_loss: 7.6610\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.5502 - val_loss: 7.5926\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 4.5427 - val_loss: 7.5106\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 4.5013 - val_loss: 7.4579\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.4953 - val_loss: 7.4596\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.5101 - val_loss: 7.3891\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.4351 - val_loss: 7.3267\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.4426 - val_loss: 7.2929\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.4284 - val_loss: 7.2464\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3883 - val_loss: 7.2230\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3601 - val_loss: 7.2034\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3366 - val_loss: 7.1897\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.3171 - val_loss: 7.1996\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.3024 - val_loss: 7.1705\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.2880 - val_loss: 7.1491\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.2655 - val_loss: 7.1094\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.2423 - val_loss: 7.0549\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.2388 - val_loss: 6.9666\n",
      "Epoch 233/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.2155 - val_loss: 6.9128\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.1874 - val_loss: 6.9058\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.1841 - val_loss: 6.8622\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 4.1583 - val_loss: 6.8425\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.1368 - val_loss: 6.8178\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 4.1175 - val_loss: 6.8476\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 4.1032 - val_loss: 6.8722\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 4.0883 - val_loss: 6.8511\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 4.0736 - val_loss: 6.8132\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 4.0727 - val_loss: 6.8077\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 4.0662 - val_loss: 6.7380\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 4.0228 - val_loss: 6.6848\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 4.0028 - val_loss: 6.6538\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 3.9785 - val_loss: 6.6658\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.9846 - val_loss: 6.6832\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.9887 - val_loss: 6.6651\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.9265 - val_loss: 6.6263\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.9045 - val_loss: 6.5685\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.8878 - val_loss: 6.5318\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.8736 - val_loss: 6.5170\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.8647 - val_loss: 6.5369\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.8375 - val_loss: 6.5284\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.8198 - val_loss: 6.5158\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.8026 - val_loss: 6.4554\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.7878 - val_loss: 6.4237\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.7653 - val_loss: 6.4001\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.7543 - val_loss: 6.3836\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.7428 - val_loss: 6.3545\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.7155 - val_loss: 6.3392\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.7024 - val_loss: 6.3296\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.6815 - val_loss: 6.3190\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.6660 - val_loss: 6.3060\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.6554 - val_loss: 6.2347\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 3.6460 - val_loss: 6.2036\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 3.6251 - val_loss: 6.2067\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 3.6121 - val_loss: 6.2035\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.5868 - val_loss: 6.2059\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.5671 - val_loss: 6.2043\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.5572 - val_loss: 6.1664\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 3.5333 - val_loss: 6.1393\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.5199 - val_loss: 6.1054\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.5052 - val_loss: 6.0793\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.4928 - val_loss: 6.0937\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.4762 - val_loss: 6.0876\n",
      "Epoch 277/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.4631 - val_loss: 6.0377\n",
      "Epoch 278/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.4773 - val_loss: 6.0549\n",
      "Epoch 279/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.4755 - val_loss: 5.9800\n",
      "Epoch 280/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.4304 - val_loss: 5.9628\n",
      "Epoch 281/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.4075 - val_loss: 5.9408\n",
      "Epoch 282/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.3845 - val_loss: 5.9418\n",
      "Epoch 283/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.3950 - val_loss: 5.9534\n",
      "Epoch 284/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.3727 - val_loss: 5.8951\n",
      "Epoch 285/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.3500 - val_loss: 5.8642\n",
      "Epoch 286/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.3283 - val_loss: 5.8452\n",
      "Epoch 287/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.3154 - val_loss: 5.8266\n",
      "Epoch 288/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.3122 - val_loss: 5.8123\n",
      "Epoch 289/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.2987 - val_loss: 5.7979\n",
      "Epoch 290/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.2834 - val_loss: 5.7919\n",
      "Epoch 291/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 3.2575 - val_loss: 5.7765\n",
      "Epoch 292/1000\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 3.2630 - val_loss: 5.7938\n",
      "Epoch 293/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 3.2404 - val_loss: 5.7643\n",
      "Epoch 294/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 3.2263 - val_loss: 5.7295\n",
      "Epoch 295/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.2138 - val_loss: 5.6372\n",
      "Epoch 296/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.1946 - val_loss: 5.5947\n",
      "Epoch 297/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.1934 - val_loss: 5.5822\n",
      "Epoch 298/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 3.1774 - val_loss: 5.5488\n",
      "Epoch 299/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.1480 - val_loss: 5.5246\n",
      "Epoch 300/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.1354 - val_loss: 5.4952\n",
      "Epoch 301/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.1241 - val_loss: 5.4985\n",
      "Epoch 302/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.1316 - val_loss: 5.4988\n",
      "Epoch 303/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.1142 - val_loss: 5.4609\n",
      "Epoch 304/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 3.0867 - val_loss: 5.4305\n",
      "Epoch 305/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.0724 - val_loss: 5.3507\n",
      "Epoch 306/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.0909 - val_loss: 5.3592\n",
      "Epoch 307/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.1089 - val_loss: 5.2817\n",
      "Epoch 308/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 3.0402 - val_loss: 5.2720\n",
      "Epoch 309/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 3.0611 - val_loss: 5.3014\n",
      "Epoch 310/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.0230 - val_loss: 5.2803\n",
      "Epoch 311/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 3.0219 - val_loss: 5.3067\n",
      "Epoch 312/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.9916 - val_loss: 5.3036\n",
      "Epoch 313/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 3.0047 - val_loss: 5.3126\n",
      "Epoch 314/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 2.9729 - val_loss: 5.2568\n",
      "Epoch 315/1000\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 2.9514 - val_loss: 5.2206\n",
      "Epoch 316/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.9394 - val_loss: 5.2073\n",
      "Epoch 317/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.9202 - val_loss: 5.1975\n",
      "Epoch 318/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.9087 - val_loss: 5.1799\n",
      "Epoch 319/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.8981 - val_loss: 5.1291\n",
      "Epoch 320/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.8842 - val_loss: 5.0636\n",
      "Epoch 321/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.8780 - val_loss: 5.0048\n",
      "Epoch 322/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.8642 - val_loss: 4.9811\n",
      "Epoch 323/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.8606 - val_loss: 4.9379\n",
      "Epoch 324/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.8444 - val_loss: 4.9259\n",
      "Epoch 325/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.8397 - val_loss: 4.9194\n",
      "Epoch 326/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 2.8290 - val_loss: 4.9087\n",
      "Epoch 327/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.8117 - val_loss: 4.8749\n",
      "Epoch 328/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.7901 - val_loss: 4.8556\n",
      "Epoch 329/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.7783 - val_loss: 4.8523\n",
      "Epoch 330/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.7766 - val_loss: 4.8150\n",
      "Epoch 331/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.7650 - val_loss: 4.7548\n",
      "Epoch 332/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.7513 - val_loss: 4.7283\n",
      "Epoch 333/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.7567 - val_loss: 4.7483\n",
      "Epoch 334/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.7212 - val_loss: 4.7376\n",
      "Epoch 335/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.7172 - val_loss: 4.7409\n",
      "Epoch 336/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 2.7051 - val_loss: 4.6796\n",
      "Epoch 337/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 2.6950 - val_loss: 4.6175\n",
      "Epoch 338/1000\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 2.6865 - val_loss: 4.5674\n",
      "Epoch 339/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 2.6763 - val_loss: 4.5483\n",
      "Epoch 340/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.6568 - val_loss: 4.5474\n",
      "Epoch 341/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.6553 - val_loss: 4.5576\n",
      "Epoch 342/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.6318 - val_loss: 4.5798\n",
      "Epoch 343/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.6284 - val_loss: 4.6215\n",
      "Epoch 344/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.6321 - val_loss: 4.6195\n",
      "Epoch 345/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.6110 - val_loss: 4.6364\n",
      "Epoch 346/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.6172 - val_loss: 4.5723\n",
      "Epoch 347/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 2.5753 - val_loss: 4.5479\n",
      "Epoch 348/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.5779 - val_loss: 4.5269\n",
      "Epoch 349/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.5659 - val_loss: 4.5145\n",
      "Epoch 350/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.5486 - val_loss: 4.4882\n",
      "Epoch 351/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.5344 - val_loss: 4.4670\n",
      "Epoch 352/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.5252 - val_loss: 4.4189\n",
      "Epoch 353/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.5160 - val_loss: 4.3815\n",
      "Epoch 354/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.5086 - val_loss: 4.3507\n",
      "Epoch 355/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.4983 - val_loss: 4.3161\n",
      "Epoch 356/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.4852 - val_loss: 4.3105\n",
      "Epoch 357/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.4846 - val_loss: 4.3239\n",
      "Epoch 358/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4597 - val_loss: 4.3307\n",
      "Epoch 359/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.4562 - val_loss: 4.3441\n",
      "Epoch 360/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.4634 - val_loss: 4.3575\n",
      "Epoch 361/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.4678 - val_loss: 4.3319\n",
      "Epoch 362/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 2.4382 - val_loss: 4.2418\n",
      "Epoch 363/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.4132 - val_loss: 4.2070\n",
      "Epoch 364/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 2.4074 - val_loss: 4.1877\n",
      "Epoch 365/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 2.3858 - val_loss: 4.1979\n",
      "Epoch 366/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.3874 - val_loss: 4.1969\n",
      "Epoch 367/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.3797 - val_loss: 4.1821\n",
      "Epoch 368/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.3699 - val_loss: 4.1686\n",
      "Epoch 369/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.3596 - val_loss: 4.1435\n",
      "Epoch 370/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.3371 - val_loss: 4.1123\n",
      "Epoch 371/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.3323 - val_loss: 4.0368\n",
      "Epoch 372/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.3253 - val_loss: 3.9871\n",
      "Epoch 373/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 2.3220 - val_loss: 3.9817\n",
      "Epoch 374/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.3285 - val_loss: 3.9477\n",
      "Epoch 375/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.2936 - val_loss: 3.9403\n",
      "Epoch 376/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.3072 - val_loss: 3.9196\n",
      "Epoch 377/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.2782 - val_loss: 3.9259\n",
      "Epoch 378/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.2655 - val_loss: 3.9518\n",
      "Epoch 379/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.2888 - val_loss: 3.9499\n",
      "Epoch 380/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.2523 - val_loss: 3.9115\n",
      "Epoch 381/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.2290 - val_loss: 3.9135\n",
      "Epoch 382/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.2217 - val_loss: 3.9106\n",
      "Epoch 383/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.2162 - val_loss: 3.9167\n",
      "Epoch 384/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.2038 - val_loss: 3.9018\n",
      "Epoch 385/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 2.1941 - val_loss: 3.8576\n",
      "Epoch 386/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.1829 - val_loss: 3.7757\n",
      "Epoch 387/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.1693 - val_loss: 3.7286\n",
      "Epoch 388/1000\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 2.1706 - val_loss: 3.6831\n",
      "Epoch 389/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.1505 - val_loss: 3.6748\n",
      "Epoch 390/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 2.1396 - val_loss: 3.6775\n",
      "Epoch 391/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.1483 - val_loss: 3.6910\n",
      "Epoch 392/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 2.1151 - val_loss: 3.6936\n",
      "Epoch 393/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 2.0986 - val_loss: 3.7155\n",
      "Epoch 394/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.1044 - val_loss: 3.7175\n",
      "Epoch 395/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 2.0877 - val_loss: 3.7058\n",
      "Epoch 396/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.0750 - val_loss: 3.6479\n",
      "Epoch 397/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.0623 - val_loss: 3.6244\n",
      "Epoch 398/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.0549 - val_loss: 3.5882\n",
      "Epoch 399/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.0458 - val_loss: 3.5649\n",
      "Epoch 400/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.0334 - val_loss: 3.5375\n",
      "Epoch 401/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 2.0226 - val_loss: 3.5345\n",
      "Epoch 402/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 2.0129 - val_loss: 3.5346\n",
      "Epoch 403/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 2.0135 - val_loss: 3.5287\n",
      "Epoch 404/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.9972 - val_loss: 3.5141\n",
      "Epoch 405/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.9930 - val_loss: 3.4881\n",
      "Epoch 406/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.9783 - val_loss: 3.4554\n",
      "Epoch 407/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.9620 - val_loss: 3.4239\n",
      "Epoch 408/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.9535 - val_loss: 3.3946\n",
      "Epoch 409/1000\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 1.9419 - val_loss: 3.3745\n",
      "Epoch 410/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1.9313 - val_loss: 3.3598\n",
      "Epoch 411/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.9225 - val_loss: 3.3494\n",
      "Epoch 412/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.9167 - val_loss: 3.3356\n",
      "Epoch 413/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.8976 - val_loss: 3.3246\n",
      "Epoch 414/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.9127 - val_loss: 3.3171\n",
      "Epoch 415/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.8764 - val_loss: 3.2758\n",
      "Epoch 416/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.8789 - val_loss: 3.2124\n",
      "Epoch 417/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.8466 - val_loss: 3.2442\n",
      "Epoch 418/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.8998 - val_loss: 3.1865\n",
      "Epoch 419/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.8477 - val_loss: 3.1556\n",
      "Epoch 420/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.8410 - val_loss: 3.1814\n",
      "Epoch 421/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.8416 - val_loss: 3.1569\n",
      "Epoch 422/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.7912 - val_loss: 3.2203\n",
      "Epoch 423/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.8314 - val_loss: 3.1677\n",
      "Epoch 424/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.7747 - val_loss: 3.1337\n",
      "Epoch 425/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.7565 - val_loss: 3.1023\n",
      "Epoch 426/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.7435 - val_loss: 3.0721\n",
      "Epoch 427/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.7319 - val_loss: 3.0563\n",
      "Epoch 428/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.7251 - val_loss: 3.0342\n",
      "Epoch 429/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.7170 - val_loss: 2.9982\n",
      "Epoch 430/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.7094 - val_loss: 2.9747\n",
      "Epoch 431/1000\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 1.7102 - val_loss: 2.9772\n",
      "Epoch 432/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.6866 - val_loss: 2.9591\n",
      "Epoch 433/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.7075 - val_loss: 2.9740\n",
      "Epoch 434/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.6820 - val_loss: 3.0000\n",
      "Epoch 435/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.6840 - val_loss: 2.9759\n",
      "Epoch 436/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.6549 - val_loss: 2.9502\n",
      "Epoch 437/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.6392 - val_loss: 2.9185\n",
      "Epoch 438/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.6199 - val_loss: 2.8948\n",
      "Epoch 439/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.6072 - val_loss: 2.8941\n",
      "Epoch 440/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.6001 - val_loss: 2.8782\n",
      "Epoch 441/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5933 - val_loss: 2.8638\n",
      "Epoch 442/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1.5796 - val_loss: 2.8440\n",
      "Epoch 443/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.5929 - val_loss: 2.8390\n",
      "Epoch 444/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5775 - val_loss: 2.7984\n",
      "Epoch 445/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.5689 - val_loss: 2.7935\n",
      "Epoch 446/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.5524 - val_loss: 2.7925\n",
      "Epoch 447/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.5361 - val_loss: 2.7795\n",
      "Epoch 448/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.5366 - val_loss: 2.7761\n",
      "Epoch 449/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.5241 - val_loss: 2.7576\n",
      "Epoch 450/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.5099 - val_loss: 2.7450\n",
      "Epoch 451/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.5056 - val_loss: 2.7301\n",
      "Epoch 452/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.4949 - val_loss: 2.7093\n",
      "Epoch 453/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.4827 - val_loss: 2.7029\n",
      "Epoch 454/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 1.4893 - val_loss: 2.6947\n",
      "Epoch 455/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.4781 - val_loss: 2.6600\n",
      "Epoch 456/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4696 - val_loss: 2.6784\n",
      "Epoch 457/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.4940 - val_loss: 2.6293\n",
      "Epoch 458/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4522 - val_loss: 2.5982\n",
      "Epoch 459/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4326 - val_loss: 2.5879\n",
      "Epoch 460/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.4469 - val_loss: 2.5872\n",
      "Epoch 461/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.4148 - val_loss: 2.5975\n",
      "Epoch 462/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.4291 - val_loss: 2.6029\n",
      "Epoch 463/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.3979 - val_loss: 2.6062\n",
      "Epoch 464/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4195 - val_loss: 2.5714\n",
      "Epoch 465/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.3931 - val_loss: 2.5277\n",
      "Epoch 466/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.3761 - val_loss: 2.5229\n",
      "Epoch 467/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.3618 - val_loss: 2.4982\n",
      "Epoch 468/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.3613 - val_loss: 2.4905\n",
      "Epoch 469/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.3537 - val_loss: 2.4876\n",
      "Epoch 470/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.3390 - val_loss: 2.4754\n",
      "Epoch 471/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.3305 - val_loss: 2.4669\n",
      "Epoch 472/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.3246 - val_loss: 2.4495\n",
      "Epoch 473/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.3298 - val_loss: 2.4260\n",
      "Epoch 474/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 1.3180 - val_loss: 2.4478\n",
      "Epoch 475/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.3569 - val_loss: 2.4609\n",
      "Epoch 476/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1.3297 - val_loss: 2.3900\n",
      "Epoch 477/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.2946 - val_loss: 2.3996\n",
      "Epoch 478/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.3145 - val_loss: 2.3634\n",
      "Epoch 479/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2705 - val_loss: 2.3387\n",
      "Epoch 480/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2663 - val_loss: 2.3139\n",
      "Epoch 481/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2527 - val_loss: 2.2996\n",
      "Epoch 482/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.2528 - val_loss: 2.2820\n",
      "Epoch 483/1000\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 1.2535 - val_loss: 2.2731\n",
      "Epoch 484/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2418 - val_loss: 2.2595\n",
      "Epoch 485/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2252 - val_loss: 2.2415\n",
      "Epoch 486/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.2205 - val_loss: 2.2240\n",
      "Epoch 487/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.2097 - val_loss: 2.2329\n",
      "Epoch 488/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.2039 - val_loss: 2.2463\n",
      "Epoch 489/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.2008 - val_loss: 2.2630\n",
      "Epoch 490/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.2068 - val_loss: 2.2477\n",
      "Epoch 491/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.1868 - val_loss: 2.2483\n",
      "Epoch 492/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.1805 - val_loss: 2.2153\n",
      "Epoch 493/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.1649 - val_loss: 2.1983\n",
      "Epoch 494/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.1703 - val_loss: 2.1730\n",
      "Epoch 495/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.1543 - val_loss: 2.1849\n",
      "Epoch 496/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.1661 - val_loss: 2.1569\n",
      "Epoch 497/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1454 - val_loss: 2.1443\n",
      "Epoch 498/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.1316 - val_loss: 2.1505\n",
      "Epoch 499/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1505 - val_loss: 2.1676\n",
      "Epoch 500/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1239 - val_loss: 2.1360\n",
      "Epoch 501/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.1132 - val_loss: 2.1294\n",
      "Epoch 502/1000\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 1.1161 - val_loss: 2.1103\n",
      "Epoch 503/1000\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1.1076 - val_loss: 2.1032\n",
      "Epoch 504/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.0963 - val_loss: 2.1088\n",
      "Epoch 505/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.0874 - val_loss: 2.1080\n",
      "Epoch 506/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1.1114 - val_loss: 2.1184\n",
      "Epoch 507/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.0856 - val_loss: 2.0747\n",
      "Epoch 508/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0892 - val_loss: 2.0997\n",
      "Epoch 509/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0931 - val_loss: 2.0515\n",
      "Epoch 510/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.0606 - val_loss: 2.0682\n",
      "Epoch 511/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.0834 - val_loss: 2.0402\n",
      "Epoch 512/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.0542 - val_loss: 2.0172\n",
      "Epoch 513/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.0430 - val_loss: 2.0155\n",
      "Epoch 514/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1.0373 - val_loss: 2.0115\n",
      "Epoch 515/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1.0304 - val_loss: 2.0121\n",
      "Epoch 516/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1.0247 - val_loss: 2.0070\n",
      "Epoch 517/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1.0206 - val_loss: 2.0141\n",
      "Epoch 518/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1.0179 - val_loss: 2.0123\n",
      "Epoch 519/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.0085 - val_loss: 2.0070\n",
      "Epoch 520/1000\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 1.0015 - val_loss: 1.9877\n",
      "Epoch 521/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.9991 - val_loss: 1.9554\n",
      "Epoch 522/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.9897 - val_loss: 1.9436\n",
      "Epoch 523/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.9860 - val_loss: 1.9205\n",
      "Epoch 524/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.9830 - val_loss: 1.9100\n",
      "Epoch 525/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.9749 - val_loss: 1.9057\n",
      "Epoch 526/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.9741 - val_loss: 1.8935\n",
      "Epoch 527/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.9670 - val_loss: 1.8852\n",
      "Epoch 528/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.9674 - val_loss: 1.8828\n",
      "Epoch 529/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.9630 - val_loss: 1.8748\n",
      "Epoch 530/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.9507 - val_loss: 1.8697\n",
      "Epoch 531/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.9463 - val_loss: 1.8530\n",
      "Epoch 532/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.9464 - val_loss: 1.8352\n",
      "Epoch 533/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.9459 - val_loss: 1.8554\n",
      "Epoch 534/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.9467 - val_loss: 1.8297\n",
      "Epoch 535/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.9261 - val_loss: 1.8104\n",
      "Epoch 536/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.9355 - val_loss: 1.8032\n",
      "Epoch 537/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.9349 - val_loss: 1.7798\n",
      "Epoch 538/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.9106 - val_loss: 1.7685\n",
      "Epoch 539/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.9129 - val_loss: 1.7796\n",
      "Epoch 540/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.9047 - val_loss: 1.7532\n",
      "Epoch 541/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.9122 - val_loss: 1.7507\n",
      "Epoch 542/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.8877 - val_loss: 1.7592\n",
      "Epoch 543/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.9042 - val_loss: 1.7624\n",
      "Epoch 544/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.8854 - val_loss: 1.7377\n",
      "Epoch 545/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.8806 - val_loss: 1.7266\n",
      "Epoch 546/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.8815 - val_loss: 1.7364\n",
      "Epoch 547/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.8813 - val_loss: 1.7126\n",
      "Epoch 548/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.9010 - val_loss: 1.7481\n",
      "Epoch 549/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.9054 - val_loss: 1.6855\n",
      "Epoch 550/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.8540 - val_loss: 1.6923\n",
      "Epoch 551/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.8763 - val_loss: 1.6760\n",
      "Epoch 552/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.8503 - val_loss: 1.6524\n",
      "Epoch 553/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.8544 - val_loss: 1.6515\n",
      "Epoch 554/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.8513 - val_loss: 1.6453\n",
      "Epoch 555/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.8400 - val_loss: 1.6749\n",
      "Epoch 556/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.8449 - val_loss: 1.6386\n",
      "Epoch 557/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.8288 - val_loss: 1.6305\n",
      "Epoch 558/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.8239 - val_loss: 1.6264\n",
      "Epoch 559/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.8195 - val_loss: 1.6345\n",
      "Epoch 560/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.8211 - val_loss: 1.6295\n",
      "Epoch 561/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.8140 - val_loss: 1.6232\n",
      "Epoch 562/1000\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.8249 - val_loss: 1.6222\n",
      "Epoch 563/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.8074 - val_loss: 1.5974\n",
      "Epoch 564/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.8825 - val_loss: 1.6297\n",
      "Epoch 565/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.8434 - val_loss: 1.5716\n",
      "Epoch 566/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.8024 - val_loss: 1.5810\n",
      "Epoch 567/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.7913 - val_loss: 1.5500\n",
      "Epoch 568/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.7958 - val_loss: 1.5437\n",
      "Epoch 569/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.7837 - val_loss: 1.5415\n",
      "Epoch 570/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.7748 - val_loss: 1.5415\n",
      "Epoch 571/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.7707 - val_loss: 1.5499\n",
      "Epoch 572/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.7644 - val_loss: 1.5438\n",
      "Epoch 573/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.7615 - val_loss: 1.5423\n",
      "Epoch 574/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.7522 - val_loss: 1.5416\n",
      "Epoch 575/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.7604 - val_loss: 1.5390\n",
      "Epoch 576/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.7665 - val_loss: 1.5564\n",
      "Epoch 577/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.7636 - val_loss: 1.5456\n",
      "Epoch 578/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.7451 - val_loss: 1.5286\n",
      "Epoch 579/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.7390 - val_loss: 1.5197\n",
      "Epoch 580/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.7351 - val_loss: 1.5133\n",
      "Epoch 581/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.7360 - val_loss: 1.5042\n",
      "Epoch 582/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.7335 - val_loss: 1.4973\n",
      "Epoch 583/1000\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.7287 - val_loss: 1.5004\n",
      "Epoch 584/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.7215 - val_loss: 1.4918\n",
      "Epoch 585/1000\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.7195 - val_loss: 1.4868\n",
      "Epoch 586/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.7203 - val_loss: 1.5078\n",
      "Epoch 587/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.7221 - val_loss: 1.4840\n",
      "Epoch 588/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.7099 - val_loss: 1.4778\n",
      "Epoch 589/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.7167 - val_loss: 1.4757\n",
      "Epoch 590/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.7155 - val_loss: 1.4676\n",
      "Epoch 591/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.7059 - val_loss: 1.4664\n",
      "Epoch 592/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6986 - val_loss: 1.4729\n",
      "Epoch 593/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.7046 - val_loss: 1.4700\n",
      "Epoch 594/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6957 - val_loss: 1.4505\n",
      "Epoch 595/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.6896 - val_loss: 1.4424\n",
      "Epoch 596/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6891 - val_loss: 1.4378\n",
      "Epoch 597/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6898 - val_loss: 1.4345\n",
      "Epoch 598/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.6961 - val_loss: 1.4368\n",
      "Epoch 599/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6833 - val_loss: 1.4313\n",
      "Epoch 600/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6834 - val_loss: 1.4450\n",
      "Epoch 601/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6817 - val_loss: 1.4106\n",
      "Epoch 602/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6825 - val_loss: 1.4049\n",
      "Epoch 603/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6737 - val_loss: 1.4211\n",
      "Epoch 604/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6897 - val_loss: 1.4079\n",
      "Epoch 605/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6707 - val_loss: 1.3887\n",
      "Epoch 606/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.6630 - val_loss: 1.3863\n",
      "Epoch 607/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.6561 - val_loss: 1.3917\n",
      "Epoch 608/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.6609 - val_loss: 1.3825\n",
      "Epoch 609/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.6554 - val_loss: 1.3659\n",
      "Epoch 610/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6765 - val_loss: 1.3672\n",
      "Epoch 611/1000\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.6637 - val_loss: 1.3533\n",
      "Epoch 612/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.6503 - val_loss: 1.3510\n",
      "Epoch 613/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6442 - val_loss: 1.3703\n",
      "Epoch 614/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.6583 - val_loss: 1.3564\n",
      "Epoch 615/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6439 - val_loss: 1.3355\n",
      "Epoch 616/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6504 - val_loss: 1.3331\n",
      "Epoch 617/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6273 - val_loss: 1.3850\n",
      "Epoch 618/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6755 - val_loss: 1.3521\n",
      "Epoch 619/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6258 - val_loss: 1.3402\n",
      "Epoch 620/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.6672 - val_loss: 1.3504\n",
      "Epoch 621/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.6480 - val_loss: 1.3239\n",
      "Epoch 622/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6208 - val_loss: 1.3329\n",
      "Epoch 623/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6301 - val_loss: 1.3209\n",
      "Epoch 624/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.6269 - val_loss: 1.3032\n",
      "Epoch 625/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6165 - val_loss: 1.2979\n",
      "Epoch 626/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6163 - val_loss: 1.2903\n",
      "Epoch 627/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6144 - val_loss: 1.2871\n",
      "Epoch 628/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6120 - val_loss: 1.2901\n",
      "Epoch 629/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.6147 - val_loss: 1.3007\n",
      "Epoch 630/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.6141 - val_loss: 1.2781\n",
      "Epoch 631/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6210 - val_loss: 1.2750\n",
      "Epoch 632/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.6088 - val_loss: 1.2724\n",
      "Epoch 633/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.6055 - val_loss: 1.2668\n",
      "Epoch 634/1000\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.6080 - val_loss: 1.2628\n",
      "Epoch 635/1000\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.6020 - val_loss: 1.2699\n",
      "Epoch 636/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.6102 - val_loss: 1.2825\n",
      "Epoch 637/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.6009 - val_loss: 1.2617\n",
      "Epoch 638/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.5947 - val_loss: 1.2598\n",
      "Epoch 639/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5993 - val_loss: 1.2580\n",
      "Epoch 640/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5937 - val_loss: 1.2556\n",
      "Epoch 641/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5927 - val_loss: 1.2523\n",
      "Epoch 642/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5881 - val_loss: 1.2429\n",
      "Epoch 643/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5893 - val_loss: 1.2340\n",
      "Epoch 644/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5989 - val_loss: 1.2258\n",
      "Epoch 645/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5866 - val_loss: 1.2393\n",
      "Epoch 646/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.5909 - val_loss: 1.2229\n",
      "Epoch 647/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5785 - val_loss: 1.2146\n",
      "Epoch 648/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5845 - val_loss: 1.2100\n",
      "Epoch 649/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5697 - val_loss: 1.2258\n",
      "Epoch 650/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.6012 - val_loss: 1.2285\n",
      "Epoch 651/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5854 - val_loss: 1.2134\n",
      "Epoch 652/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5862 - val_loss: 1.2045\n",
      "Epoch 653/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5674 - val_loss: 1.2228\n",
      "Epoch 654/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5749 - val_loss: 1.2033\n",
      "Epoch 655/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5776 - val_loss: 1.2289\n",
      "Epoch 656/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5973 - val_loss: 1.2015\n",
      "Epoch 657/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5787 - val_loss: 1.2436\n",
      "Epoch 658/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5866 - val_loss: 1.2095\n",
      "Epoch 659/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5593 - val_loss: 1.2001\n",
      "Epoch 660/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5528 - val_loss: 1.1977\n",
      "Epoch 661/1000\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.5578 - val_loss: 1.1972\n",
      "Epoch 662/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5576 - val_loss: 1.1958\n",
      "Epoch 663/1000\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.5457 - val_loss: 1.2029\n",
      "Epoch 664/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5481 - val_loss: 1.2026\n",
      "Epoch 665/1000\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.5457 - val_loss: 1.1967\n",
      "Epoch 666/1000\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.5637 - val_loss: 1.2057\n",
      "Epoch 667/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.5405 - val_loss: 1.2001\n",
      "Epoch 668/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5497 - val_loss: 1.2229\n",
      "Epoch 669/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5582 - val_loss: 1.1888\n",
      "Epoch 670/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5344 - val_loss: 1.1912\n",
      "Epoch 671/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5474 - val_loss: 1.1803\n",
      "Epoch 672/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5266 - val_loss: 1.1999\n",
      "Epoch 673/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5540 - val_loss: 1.1962\n",
      "Epoch 674/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5309 - val_loss: 1.1733\n",
      "Epoch 675/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5385 - val_loss: 1.1684\n",
      "Epoch 676/1000\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.5275 - val_loss: 1.1713\n",
      "Epoch 677/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5261 - val_loss: 1.1629\n",
      "Epoch 678/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5238 - val_loss: 1.1693\n",
      "Epoch 679/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5359 - val_loss: 1.1705\n",
      "Epoch 680/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5326 - val_loss: 1.1607\n",
      "Epoch 681/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5197 - val_loss: 1.1647\n",
      "Epoch 682/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5170 - val_loss: 1.1592\n",
      "Epoch 683/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5130 - val_loss: 1.1591\n",
      "Epoch 684/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5220 - val_loss: 1.1616\n",
      "Epoch 685/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5231 - val_loss: 1.1594\n",
      "Epoch 686/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5222 - val_loss: 1.1499\n",
      "Epoch 687/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5107 - val_loss: 1.1472\n",
      "Epoch 688/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5093 - val_loss: 1.1471\n",
      "Epoch 689/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5082 - val_loss: 1.1484\n",
      "Epoch 690/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5063 - val_loss: 1.1437\n",
      "Epoch 691/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5116 - val_loss: 1.1478\n",
      "Epoch 692/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5110 - val_loss: 1.1419\n",
      "Epoch 693/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5272 - val_loss: 1.1518\n",
      "Epoch 694/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5048 - val_loss: 1.1476\n",
      "Epoch 695/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5135 - val_loss: 1.1353\n",
      "Epoch 696/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5018 - val_loss: 1.1410\n",
      "Epoch 697/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.5042 - val_loss: 1.1318\n",
      "Epoch 698/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4954 - val_loss: 1.1317\n",
      "Epoch 699/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5006 - val_loss: 1.1272\n",
      "Epoch 700/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4980 - val_loss: 1.1297\n",
      "Epoch 701/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4987 - val_loss: 1.1234\n",
      "Epoch 702/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4968 - val_loss: 1.1260\n",
      "Epoch 703/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5047 - val_loss: 1.1183\n",
      "Epoch 704/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4912 - val_loss: 1.1200\n",
      "Epoch 705/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4937 - val_loss: 1.1171\n",
      "Epoch 706/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4903 - val_loss: 1.1110\n",
      "Epoch 707/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4931 - val_loss: 1.1053\n",
      "Epoch 708/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4895 - val_loss: 1.1071\n",
      "Epoch 709/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4922 - val_loss: 1.1064\n",
      "Epoch 710/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4848 - val_loss: 1.0985\n",
      "Epoch 711/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4914 - val_loss: 1.1040\n",
      "Epoch 712/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4879 - val_loss: 1.1000\n",
      "Epoch 713/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4929 - val_loss: 1.1210\n",
      "Epoch 714/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5000 - val_loss: 1.0957\n",
      "Epoch 715/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4764 - val_loss: 1.1124\n",
      "Epoch 716/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5050 - val_loss: 1.0958\n",
      "Epoch 717/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4808 - val_loss: 1.0970\n",
      "Epoch 718/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4841 - val_loss: 1.0927\n",
      "Epoch 719/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4777 - val_loss: 1.0923\n",
      "Epoch 720/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4875 - val_loss: 1.0897\n",
      "Epoch 721/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4858 - val_loss: 1.0874\n",
      "Epoch 722/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4770 - val_loss: 1.0840\n",
      "Epoch 723/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4766 - val_loss: 1.0839\n",
      "Epoch 724/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4797 - val_loss: 1.0803\n",
      "Epoch 725/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4837 - val_loss: 1.0876\n",
      "Epoch 726/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4841 - val_loss: 1.0775\n",
      "Epoch 727/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4874 - val_loss: 1.1152\n",
      "Epoch 728/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4807 - val_loss: 1.0852\n",
      "Epoch 729/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5080 - val_loss: 1.1056\n",
      "Epoch 730/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4906 - val_loss: 1.0811\n",
      "Epoch 731/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4801 - val_loss: 1.0866\n",
      "Epoch 732/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4698 - val_loss: 1.0782\n",
      "Epoch 733/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4794 - val_loss: 1.0850\n",
      "Epoch 734/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5032 - val_loss: 1.0798\n",
      "Epoch 735/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4719 - val_loss: 1.0799\n",
      "Epoch 736/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4717 - val_loss: 1.0674\n",
      "Epoch 737/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4644 - val_loss: 1.0666\n",
      "Epoch 738/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4661 - val_loss: 1.0624\n",
      "Epoch 739/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4755 - val_loss: 1.0663\n",
      "Epoch 740/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4710 - val_loss: 1.0508\n",
      "Epoch 741/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4620 - val_loss: 1.0528\n",
      "Epoch 742/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4647 - val_loss: 1.0466\n",
      "Epoch 743/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4604 - val_loss: 1.0483\n",
      "Epoch 744/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4668 - val_loss: 1.0443\n",
      "Epoch 745/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4553 - val_loss: 1.0552\n",
      "Epoch 746/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4634 - val_loss: 1.0534\n",
      "Epoch 747/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4590 - val_loss: 1.0555\n",
      "Epoch 748/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4577 - val_loss: 1.0534\n",
      "Epoch 749/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4581 - val_loss: 1.0508\n",
      "Epoch 750/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4553 - val_loss: 1.0465\n",
      "Epoch 751/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4630 - val_loss: 1.0437\n",
      "Epoch 752/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4581 - val_loss: 1.0571\n",
      "Epoch 753/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4593 - val_loss: 1.0412\n",
      "Epoch 754/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4730 - val_loss: 1.0477\n",
      "Epoch 755/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4519 - val_loss: 1.0568\n",
      "Epoch 756/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4600 - val_loss: 1.0471\n",
      "Epoch 757/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4530 - val_loss: 1.0419\n",
      "Epoch 758/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4504 - val_loss: 1.0393\n",
      "Epoch 759/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4503 - val_loss: 1.0390\n",
      "Epoch 760/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4498 - val_loss: 1.0405\n",
      "Epoch 761/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4479 - val_loss: 1.0390\n",
      "Epoch 762/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4479 - val_loss: 1.0375\n",
      "Epoch 763/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4559 - val_loss: 1.0364\n",
      "Epoch 764/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4441 - val_loss: 1.0538\n",
      "Epoch 765/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4657 - val_loss: 1.0372\n",
      "Epoch 766/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4649 - val_loss: 1.0516\n",
      "Epoch 767/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4646 - val_loss: 1.0289\n",
      "Epoch 768/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4454 - val_loss: 1.0254\n",
      "Epoch 769/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4566 - val_loss: 1.0263\n",
      "Epoch 770/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4471 - val_loss: 1.0209\n",
      "Epoch 771/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4465 - val_loss: 1.0251\n",
      "Epoch 772/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4451 - val_loss: 1.0276\n",
      "Epoch 773/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4564 - val_loss: 1.0449\n",
      "Epoch 774/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4548 - val_loss: 1.0357\n",
      "Epoch 775/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4558 - val_loss: 1.0251\n",
      "Epoch 776/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4478 - val_loss: 1.0416\n",
      "Epoch 777/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4480 - val_loss: 1.0291\n",
      "Epoch 778/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4677 - val_loss: 1.0357\n",
      "Epoch 779/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4365 - val_loss: 1.0566\n",
      "Epoch 780/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4946 - val_loss: 1.0562\n",
      "Epoch 781/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4575 - val_loss: 1.0613\n",
      "Epoch 782/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4953 - val_loss: 1.0267\n",
      "Epoch 783/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4413 - val_loss: 1.0485\n",
      "Epoch 784/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4493 - val_loss: 1.0253\n",
      "Epoch 785/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4415 - val_loss: 1.0313\n",
      "Epoch 786/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4456 - val_loss: 1.0307\n",
      "Epoch 787/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.4433 - val_loss: 1.0275\n",
      "Epoch 788/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4403 - val_loss: 1.0278\n",
      "Epoch 789/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4386 - val_loss: 1.0303\n",
      "Epoch 790/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4391 - val_loss: 1.0271\n",
      "Epoch 791/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4387 - val_loss: 1.0259\n",
      "Epoch 792/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4346 - val_loss: 1.0341\n",
      "Epoch 793/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4394 - val_loss: 1.0379\n",
      "Epoch 794/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4399 - val_loss: 1.0305\n",
      "Epoch 795/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4391 - val_loss: 1.0273\n",
      "Epoch 796/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4364 - val_loss: 1.0263\n",
      "Epoch 797/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4337 - val_loss: 1.0242\n",
      "Epoch 798/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4376 - val_loss: 1.0241\n",
      "Epoch 799/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4415 - val_loss: 1.0369\n",
      "Epoch 800/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4436 - val_loss: 1.0306\n",
      "Epoch 801/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.4370 - val_loss: 1.0369\n",
      "Epoch 802/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4419 - val_loss: 1.0304\n",
      "Epoch 803/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4350 - val_loss: 1.0238\n",
      "Epoch 804/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4332 - val_loss: 1.0208\n",
      "Epoch 805/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4316 - val_loss: 1.0200\n",
      "Epoch 806/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4312 - val_loss: 1.0179\n",
      "Epoch 807/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4320 - val_loss: 1.0158\n",
      "Epoch 808/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4308 - val_loss: 1.0142\n",
      "Epoch 809/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4321 - val_loss: 1.0133\n",
      "Epoch 810/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4347 - val_loss: 1.0230\n",
      "Epoch 811/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4400 - val_loss: 1.0236\n",
      "Epoch 812/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4404 - val_loss: 1.0143\n",
      "Epoch 813/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4293 - val_loss: 1.0123\n",
      "Epoch 814/1000\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.4307 - val_loss: 1.0133\n",
      "Epoch 815/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4351 - val_loss: 1.0134\n",
      "Epoch 816/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4285 - val_loss: 1.0305\n",
      "Epoch 817/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4393 - val_loss: 1.0159\n",
      "Epoch 818/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4282 - val_loss: 1.0136\n",
      "Epoch 819/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4347 - val_loss: 1.0170\n",
      "Epoch 820/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4262 - val_loss: 1.0181\n",
      "Epoch 821/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4482 - val_loss: 1.0227\n",
      "Epoch 822/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4407 - val_loss: 1.0324\n",
      "Epoch 823/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4421 - val_loss: 1.0161\n",
      "Epoch 824/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4283 - val_loss: 1.0216\n",
      "Epoch 825/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4303 - val_loss: 1.0133\n",
      "Epoch 826/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4290 - val_loss: 1.0186\n",
      "Epoch 827/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4324 - val_loss: 1.0165\n",
      "Epoch 828/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4312 - val_loss: 1.0317\n",
      "Epoch 829/1000\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4475 - val_loss: 1.0076\n",
      "Epoch 830/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4330 - val_loss: 1.0111\n",
      "Epoch 831/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4249 - val_loss: 1.0128\n",
      "Epoch 832/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4320 - val_loss: 1.0064\n",
      "Epoch 833/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4244 - val_loss: 1.0028\n",
      "Epoch 834/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4254 - val_loss: 1.0016\n",
      "Epoch 835/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4256 - val_loss: 0.9997\n",
      "Epoch 836/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4243 - val_loss: 1.0003\n",
      "Epoch 837/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4263 - val_loss: 0.9989\n",
      "Epoch 838/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4305 - val_loss: 1.0007\n",
      "Epoch 839/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4231 - val_loss: 1.0064\n",
      "Epoch 840/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4274 - val_loss: 1.0071\n",
      "Epoch 841/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4289 - val_loss: 1.0110\n",
      "Epoch 842/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4439 - val_loss: 1.0341\n",
      "Epoch 843/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4333 - val_loss: 1.0137\n",
      "Epoch 844/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4334 - val_loss: 1.0292\n",
      "Epoch 845/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4393 - val_loss: 1.0134\n",
      "Epoch 846/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4387 - val_loss: 1.0264\n",
      "Epoch 847/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4325 - val_loss: 1.0250\n",
      "Epoch 848/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4341 - val_loss: 1.0184\n",
      "Epoch 849/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4225 - val_loss: 1.0157\n",
      "Epoch 850/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4204 - val_loss: 1.0154\n",
      "Epoch 851/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4226 - val_loss: 1.0184\n",
      "Epoch 852/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4247 - val_loss: 1.0153\n",
      "Epoch 853/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4239 - val_loss: 1.0278\n",
      "Epoch 854/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4298 - val_loss: 1.0140\n",
      "Epoch 855/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4271 - val_loss: 1.0151\n",
      "Epoch 856/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4228 - val_loss: 1.0116\n",
      "Epoch 857/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4234 - val_loss: 1.0102\n",
      "Epoch 858/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.4206 - val_loss: 1.0088\n",
      "Epoch 859/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4201 - val_loss: 1.0045\n",
      "Epoch 860/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4247 - val_loss: 1.0125\n",
      "Epoch 861/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4248 - val_loss: 1.0074\n",
      "Epoch 862/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4199 - val_loss: 1.0094\n",
      "Epoch 863/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4186 - val_loss: 1.0123\n",
      "Epoch 864/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4241 - val_loss: 1.0142\n",
      "Epoch 865/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4211 - val_loss: 1.0041\n",
      "Epoch 866/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4220 - val_loss: 1.0002\n",
      "Epoch 867/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4184 - val_loss: 0.9977\n",
      "Epoch 868/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4246 - val_loss: 1.0008\n",
      "Epoch 869/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4432 - val_loss: 1.0175\n",
      "Epoch 870/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4262 - val_loss: 1.0155\n",
      "Epoch 871/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4257 - val_loss: 1.0031\n",
      "Epoch 872/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4290 - val_loss: 1.0082\n",
      "Epoch 873/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4311 - val_loss: 1.0163\n",
      "Epoch 874/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4239 - val_loss: 1.0088\n",
      "Epoch 875/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.4365 - val_loss: 1.0393\n",
      "Epoch 876/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4413 - val_loss: 1.0114\n",
      "Epoch 877/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4320 - val_loss: 1.0298\n",
      "Epoch 878/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4242 - val_loss: 1.0133\n",
      "Epoch 879/1000\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.4218 - val_loss: 1.0050\n",
      "Epoch 880/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4238 - val_loss: 1.0058\n",
      "Epoch 881/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4162 - val_loss: 1.0153\n",
      "Epoch 882/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4557 - val_loss: 1.0136\n",
      "Epoch 883/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4282 - val_loss: 1.0076\n",
      "Epoch 884/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4282 - val_loss: 0.9944\n",
      "Epoch 885/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4250 - val_loss: 0.9980\n",
      "Epoch 886/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4159 - val_loss: 1.0002\n",
      "Epoch 887/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4137 - val_loss: 1.0041\n",
      "Epoch 888/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4149 - val_loss: 1.0077\n",
      "Epoch 889/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4148 - val_loss: 1.0035\n",
      "Epoch 890/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4227 - val_loss: 1.0004\n",
      "Epoch 891/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4389 - val_loss: 1.0067\n",
      "Epoch 892/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4288 - val_loss: 1.0497\n",
      "Epoch 893/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4518 - val_loss: 0.9957\n",
      "Epoch 894/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4298 - val_loss: 1.0329\n",
      "Epoch 895/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4355 - val_loss: 0.9973\n",
      "Epoch 896/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4163 - val_loss: 0.9981\n",
      "Epoch 897/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4172 - val_loss: 1.0025\n",
      "Epoch 898/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4146 - val_loss: 1.0043\n",
      "Epoch 899/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4193 - val_loss: 1.0100\n",
      "Epoch 900/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4182 - val_loss: 1.0033\n",
      "Epoch 901/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4453 - val_loss: 1.0187\n",
      "Epoch 902/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4162 - val_loss: 1.0305\n",
      "Epoch 903/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4679 - val_loss: 1.0041\n",
      "Epoch 904/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4182 - val_loss: 1.0165\n",
      "Epoch 905/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4265 - val_loss: 1.0044\n",
      "Epoch 906/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4262 - val_loss: 1.0040\n",
      "Epoch 907/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4120 - val_loss: 1.0039\n",
      "Epoch 908/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4132 - val_loss: 1.0044\n",
      "Epoch 909/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4206 - val_loss: 1.0120\n",
      "Epoch 910/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4180 - val_loss: 1.0034\n",
      "Epoch 911/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4154 - val_loss: 1.0005\n",
      "Epoch 912/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4120 - val_loss: 1.0108\n",
      "Epoch 913/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4215 - val_loss: 0.9986\n",
      "Epoch 914/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4163 - val_loss: 0.9995\n",
      "Epoch 915/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4180 - val_loss: 1.0046\n",
      "Epoch 916/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4081 - val_loss: 1.0098\n",
      "Epoch 917/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4192 - val_loss: 1.0000\n",
      "Epoch 918/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4175 - val_loss: 1.0217\n",
      "Epoch 919/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4284 - val_loss: 1.0033\n",
      "Epoch 920/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4150 - val_loss: 1.0074\n",
      "Epoch 921/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4194 - val_loss: 1.0113\n",
      "Epoch 922/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4146 - val_loss: 1.0087\n",
      "Epoch 923/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4092 - val_loss: 1.0051\n",
      "Epoch 924/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4174 - val_loss: 1.0044\n",
      "Epoch 925/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4252 - val_loss: 1.0184\n",
      "Epoch 926/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4182 - val_loss: 1.0180\n",
      "Epoch 927/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4226 - val_loss: 1.0024\n",
      "Epoch 928/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4200 - val_loss: 1.0041\n",
      "Epoch 929/1000\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4073 - val_loss: 1.0256\n",
      "Epoch 930/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4342 - val_loss: 0.9973\n",
      "Epoch 931/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4093 - val_loss: 0.9943\n",
      "Epoch 932/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4125 - val_loss: 0.9921\n",
      "Epoch 933/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4100 - val_loss: 0.9958\n",
      "Epoch 934/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4098 - val_loss: 1.0043\n",
      "Epoch 935/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4161 - val_loss: 0.9977\n",
      "Epoch 936/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4104 - val_loss: 0.9973\n",
      "Epoch 937/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4100 - val_loss: 0.9941\n",
      "Epoch 938/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4116 - val_loss: 0.9941\n",
      "Epoch 939/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4081 - val_loss: 1.0107\n",
      "Epoch 940/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4466 - val_loss: 1.0133\n",
      "Epoch 941/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4168 - val_loss: 1.0082\n",
      "Epoch 942/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4125 - val_loss: 1.0021\n",
      "Epoch 943/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4096 - val_loss: 1.0023\n",
      "Epoch 944/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4108 - val_loss: 1.0024\n",
      "Epoch 945/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4128 - val_loss: 1.0068\n",
      "Epoch 946/1000\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4123 - val_loss: 0.9988\n",
      "Epoch 947/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4313 - val_loss: 0.9952\n",
      "Epoch 948/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4083 - val_loss: 0.9975\n",
      "Epoch 949/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4113 - val_loss: 0.9894\n",
      "Epoch 950/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4127 - val_loss: 0.9907\n",
      "Epoch 951/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4100 - val_loss: 0.9927\n",
      "Epoch 952/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4164 - val_loss: 1.0051\n",
      "Epoch 953/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4043 - val_loss: 1.0161\n",
      "Epoch 954/1000\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4265 - val_loss: 1.0041\n",
      "Epoch 955/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4444 - val_loss: 1.0393\n",
      "Epoch 956/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4283 - val_loss: 1.0134\n",
      "Epoch 957/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4279 - val_loss: 0.9997\n",
      "Epoch 958/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4114 - val_loss: 1.0170\n",
      "Epoch 959/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4365 - val_loss: 1.0025\n",
      "Epoch 960/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4030 - val_loss: 1.0111\n",
      "Epoch 961/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4229 - val_loss: 0.9963\n",
      "Epoch 962/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4178 - val_loss: 1.0006\n",
      "Epoch 963/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4068 - val_loss: 1.0218\n",
      "Epoch 964/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4233 - val_loss: 1.0060\n",
      "Epoch 965/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4159 - val_loss: 1.0155\n",
      "Epoch 966/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4175 - val_loss: 1.0135\n",
      "Epoch 967/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4123 - val_loss: 1.0082\n",
      "Epoch 968/1000\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.4144 - val_loss: 1.0048\n",
      "Epoch 969/1000\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4097 - val_loss: 1.0049\n",
      "Epoch 970/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4409 - val_loss: 1.0073\n",
      "Epoch 971/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4006 - val_loss: 1.0418\n",
      "Epoch 972/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4539 - val_loss: 0.9962\n",
      "Epoch 973/1000\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4067 - val_loss: 1.0153\n",
      "Epoch 974/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4175 - val_loss: 1.0040\n",
      "Epoch 975/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4333 - val_loss: 0.9932\n",
      "Epoch 976/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4153 - val_loss: 1.0060\n",
      "Epoch 977/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4255 - val_loss: 0.9850\n",
      "Epoch 978/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4085 - val_loss: 0.9898\n",
      "Epoch 979/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4238 - val_loss: 0.9829\n",
      "Epoch 980/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4101 - val_loss: 0.9805\n",
      "Epoch 981/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4094 - val_loss: 0.9853\n",
      "Epoch 982/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4072 - val_loss: 0.9820\n",
      "Epoch 983/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4179 - val_loss: 1.0028\n",
      "Epoch 984/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4213 - val_loss: 0.9897\n",
      "Epoch 985/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4100 - val_loss: 0.9938\n",
      "Epoch 986/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4227 - val_loss: 1.0381\n",
      "Epoch 987/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4352 - val_loss: 1.0028\n",
      "Epoch 988/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.4081 - val_loss: 1.0256\n",
      "Epoch 989/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4232 - val_loss: 1.0034\n",
      "Epoch 990/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4045 - val_loss: 1.0025\n",
      "Epoch 991/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4257 - val_loss: 1.0004\n",
      "Epoch 992/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4157 - val_loss: 1.0209\n",
      "Epoch 993/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4164 - val_loss: 1.0054\n",
      "Epoch 994/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4204 - val_loss: 0.9984\n",
      "Epoch 995/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4263 - val_loss: 1.0145\n",
      "Epoch 996/1000\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4199 - val_loss: 1.0005\n",
      "Epoch 997/1000\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.4139 - val_loss: 1.0038\n",
      "Epoch 998/1000\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.4051 - val_loss: 1.0039\n",
      "Epoch 999/1000\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4076 - val_loss: 1.0070\n",
      "Epoch 1000/1000\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4121 - val_loss: 1.0062\n"
     ]
    }
   ],
   "source": [
    "neuralnet_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# TensorBoard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "history = neuralnet_model.fit(X_Train, Y_Train, epochs=1000, validation_data=(X_Test, Y_Test), \n",
    "                    verbose=1, callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot training & validation loss values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Squared Error on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0062\n",
      "Mean Squared Error on Test Data: 1.0062353610992432\n"
     ]
    }
   ],
   "source": [
    "test_loss = neuralnet_model.evaluate(X_Test, Y_Test, verbose=1)\n",
    "\n",
    "print(f\"Mean Squared Error on Test Data: {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save The Final Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralnet_model.save_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local The Final Model Weights from Saved `.h5` File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new instance of the same model\n",
    "new_model = NeuralNetwork()\n",
    "\n",
    "# Call the model on some data (this could be a batch of your actual data or dummy data)\n",
    "dummy_data = tf.zeros((1, 3))  # Assuming the input shape is (None, 3)\n",
    "new_model(dummy_data)\n",
    "\n",
    "# Load the previously saved weights\n",
    "new_model.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the entire model to the TensorFlow SavedModel format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mymodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mymodel/assets\n"
     ]
    }
   ],
   "source": [
    "neuralnet_model.save('mymodel', save_format='tf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the entire model from the TensorFlow SavedModel format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('mymodel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamkernel",
   "language": "python",
   "name": "streamkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
