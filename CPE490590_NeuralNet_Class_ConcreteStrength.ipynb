{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for Prediction using TensorFlow 2.0 (Objected-Oriented)\n",
    "## CPE 490 590 \n",
    "### Author: Rahul Bhadani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Serif'\n",
    "plt.rcParams['font.size'] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 16:01:54.371140: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-04 16:01:54.373754: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 16:01:54.402797: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-04 16:01:54.402820: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-04 16:01:54.404018: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-04 16:01:54.409289: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-04 16:01:54.409647: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-04 16:01:54.975187: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset/Concrete_Compressive_Strength/Concrete_Data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['Concrete compressive strength(MPa, megapascals) ']]\n",
    "x = df.drop('Concrete compressive strength(MPa, megapascals) ', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Dataset into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(x, y, test_size = 1/3, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Class for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 16:01:56.947572: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "class NeuralNetwork(Model):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = Dense(4, activation='relu')\n",
    "        self.layer2 = Dense(2, activation='relu')\n",
    "        self.layer3 = Dense(3, activation='relu')\n",
    "        self.output_layer = Dense(1)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "neuralnet_model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "22/22 [==============================] - 1s 8ms/step - loss: 1555.0266 - val_loss: 1544.8274\n",
      "Epoch 2/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1533.0880 - val_loss: 1511.9611\n",
      "Epoch 3/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 1454.1069 - val_loss: 1385.5416\n",
      "Epoch 4/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 1251.0408 - val_loss: 1107.5192\n",
      "Epoch 5/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 922.3597 - val_loss: 739.1368\n",
      "Epoch 6/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 596.9347 - val_loss: 481.9496\n",
      "Epoch 7/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 459.2960 - val_loss: 415.1609\n",
      "Epoch 8/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 434.5749 - val_loss: 399.4305\n",
      "Epoch 9/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 418.4568 - val_loss: 385.2382\n",
      "Epoch 10/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 405.5124 - val_loss: 373.9031\n",
      "Epoch 11/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 394.0222 - val_loss: 362.0756\n",
      "Epoch 12/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 384.5285 - val_loss: 352.7188\n",
      "Epoch 13/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 375.8551 - val_loss: 347.3291\n",
      "Epoch 14/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 368.5704 - val_loss: 339.2911\n",
      "Epoch 15/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 362.3588 - val_loss: 331.2126\n",
      "Epoch 16/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 356.0322 - val_loss: 326.1402\n",
      "Epoch 17/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 350.2436 - val_loss: 321.0137\n",
      "Epoch 18/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 345.6362 - val_loss: 315.9573\n",
      "Epoch 19/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 342.3144 - val_loss: 312.8164\n",
      "Epoch 20/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 337.0107 - val_loss: 306.2097\n",
      "Epoch 21/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 332.4317 - val_loss: 303.8498\n",
      "Epoch 22/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 330.4499 - val_loss: 301.1083\n",
      "Epoch 23/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 325.5058 - val_loss: 296.4525\n",
      "Epoch 24/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 322.9078 - val_loss: 293.2411\n",
      "Epoch 25/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 319.9745 - val_loss: 291.2812\n",
      "Epoch 26/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 316.4510 - val_loss: 287.7016\n",
      "Epoch 27/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 313.9809 - val_loss: 285.8574\n",
      "Epoch 28/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 311.5290 - val_loss: 283.0633\n",
      "Epoch 29/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 308.7137 - val_loss: 280.6325\n",
      "Epoch 30/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 306.3346 - val_loss: 278.6243\n",
      "Epoch 31/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 303.7530 - val_loss: 275.6193\n",
      "Epoch 32/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 302.2192 - val_loss: 273.7707\n",
      "Epoch 33/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 299.8529 - val_loss: 271.7973\n",
      "Epoch 34/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 297.7438 - val_loss: 271.0778\n",
      "Epoch 35/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 295.0964 - val_loss: 267.2233\n",
      "Epoch 36/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 294.6341 - val_loss: 265.8279\n",
      "Epoch 37/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 291.4687 - val_loss: 264.0720\n",
      "Epoch 38/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 289.7485 - val_loss: 261.8715\n",
      "Epoch 39/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 287.9924 - val_loss: 260.0100\n",
      "Epoch 40/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 286.3754 - val_loss: 259.5150\n",
      "Epoch 41/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 284.7592 - val_loss: 256.9286\n",
      "Epoch 42/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 283.6820 - val_loss: 257.0330\n",
      "Epoch 43/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 282.2448 - val_loss: 252.9010\n",
      "Epoch 44/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 279.2843 - val_loss: 253.1084\n",
      "Epoch 45/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 278.0337 - val_loss: 250.6647\n",
      "Epoch 46/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 276.3918 - val_loss: 248.8123\n",
      "Epoch 47/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 275.3023 - val_loss: 247.2532\n",
      "Epoch 48/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 273.5743 - val_loss: 246.2745\n",
      "Epoch 49/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 272.2523 - val_loss: 245.1910\n",
      "Epoch 50/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 271.5076 - val_loss: 242.4677\n",
      "Epoch 51/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 269.1437 - val_loss: 242.5569\n",
      "Epoch 52/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 267.5714 - val_loss: 240.3483\n",
      "Epoch 53/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 266.5184 - val_loss: 239.2320\n",
      "Epoch 54/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 265.3752 - val_loss: 236.8873\n",
      "Epoch 55/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 263.5067 - val_loss: 237.0405\n",
      "Epoch 56/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 261.9790 - val_loss: 235.2489\n",
      "Epoch 57/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 260.5954 - val_loss: 233.4666\n",
      "Epoch 58/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 259.3146 - val_loss: 232.5282\n",
      "Epoch 59/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 258.0044 - val_loss: 232.3882\n",
      "Epoch 60/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 256.6375 - val_loss: 229.4869\n",
      "Epoch 61/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 255.3919 - val_loss: 228.6754\n",
      "Epoch 62/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 253.9983 - val_loss: 226.3017\n",
      "Epoch 63/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 253.5548 - val_loss: 226.5107\n",
      "Epoch 64/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 251.4238 - val_loss: 224.2652\n",
      "Epoch 65/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 249.9679 - val_loss: 223.8486\n",
      "Epoch 66/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 248.7338 - val_loss: 222.0381\n",
      "Epoch 67/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 247.5948 - val_loss: 220.9161\n",
      "Epoch 68/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 246.5364 - val_loss: 218.9478\n",
      "Epoch 69/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 246.3996 - val_loss: 218.6863\n",
      "Epoch 70/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 243.5701 - val_loss: 217.7259\n",
      "Epoch 71/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 242.1123 - val_loss: 215.5068\n",
      "Epoch 72/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 241.6000 - val_loss: 215.3551\n",
      "Epoch 73/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 239.2560 - val_loss: 212.8867\n",
      "Epoch 74/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 238.3595 - val_loss: 212.2613\n",
      "Epoch 75/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 237.9588 - val_loss: 210.5048\n",
      "Epoch 76/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 236.0527 - val_loss: 210.3215\n",
      "Epoch 77/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 234.4290 - val_loss: 208.0014\n",
      "Epoch 78/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 232.9732 - val_loss: 207.5799\n",
      "Epoch 79/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 231.7236 - val_loss: 206.0961\n",
      "Epoch 80/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 230.3762 - val_loss: 204.1559\n",
      "Epoch 81/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 229.6209 - val_loss: 202.5231\n",
      "Epoch 82/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 228.1274 - val_loss: 201.9751\n",
      "Epoch 83/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 226.4957 - val_loss: 200.0509\n",
      "Epoch 84/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 225.2804 - val_loss: 199.1820\n",
      "Epoch 85/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 223.9896 - val_loss: 197.4310\n",
      "Epoch 86/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 222.2373 - val_loss: 197.2268\n",
      "Epoch 87/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 221.0918 - val_loss: 194.9381\n",
      "Epoch 88/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 219.6786 - val_loss: 194.8400\n",
      "Epoch 89/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 218.2896 - val_loss: 191.9818\n",
      "Epoch 90/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 216.8802 - val_loss: 190.7653\n",
      "Epoch 91/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 215.2924 - val_loss: 189.8986\n",
      "Epoch 92/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 214.0306 - val_loss: 189.3774\n",
      "Epoch 93/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 213.2095 - val_loss: 187.0117\n",
      "Epoch 94/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 211.3353 - val_loss: 186.0087\n",
      "Epoch 95/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 210.6244 - val_loss: 183.4484\n",
      "Epoch 96/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 208.9086 - val_loss: 183.7346\n",
      "Epoch 97/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 206.7801 - val_loss: 181.6211\n",
      "Epoch 98/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 205.1679 - val_loss: 179.1428\n",
      "Epoch 99/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 203.6579 - val_loss: 178.8573\n",
      "Epoch 100/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 202.3033 - val_loss: 177.5098\n",
      "Epoch 101/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 200.8853 - val_loss: 175.1022\n",
      "Epoch 102/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 199.3898 - val_loss: 174.0822\n",
      "Epoch 103/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 198.0740 - val_loss: 172.7857\n",
      "Epoch 104/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 196.9220 - val_loss: 171.7291\n",
      "Epoch 105/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 195.8875 - val_loss: 169.4694\n",
      "Epoch 106/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 193.7527 - val_loss: 168.8121\n",
      "Epoch 107/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 191.8746 - val_loss: 166.9643\n",
      "Epoch 108/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 190.3007 - val_loss: 165.2666\n",
      "Epoch 109/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 188.5526 - val_loss: 163.5614\n",
      "Epoch 110/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 187.4277 - val_loss: 161.2741\n",
      "Epoch 111/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 185.4974 - val_loss: 162.1776\n",
      "Epoch 112/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 184.1318 - val_loss: 158.9543\n",
      "Epoch 113/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 182.4778 - val_loss: 158.3154\n",
      "Epoch 114/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 180.9636 - val_loss: 155.5473\n",
      "Epoch 115/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 179.6591 - val_loss: 153.8624\n",
      "Epoch 116/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 177.7512 - val_loss: 154.7431\n",
      "Epoch 117/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 176.6327 - val_loss: 150.6808\n",
      "Epoch 118/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 175.0670 - val_loss: 149.9354\n",
      "Epoch 119/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 173.1220 - val_loss: 148.3979\n",
      "Epoch 120/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 172.1632 - val_loss: 147.4785\n",
      "Epoch 121/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 169.9904 - val_loss: 145.9207\n",
      "Epoch 122/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 168.7123 - val_loss: 143.9746\n",
      "Epoch 123/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 167.1438 - val_loss: 143.2107\n",
      "Epoch 124/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 166.0119 - val_loss: 141.5452\n",
      "Epoch 125/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 165.2540 - val_loss: 140.6859\n",
      "Epoch 126/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 163.2669 - val_loss: 139.1992\n",
      "Epoch 127/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 161.5590 - val_loss: 138.4337\n",
      "Epoch 128/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 160.2117 - val_loss: 137.4176\n",
      "Epoch 129/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 159.8533 - val_loss: 135.6428\n",
      "Epoch 130/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 157.5364 - val_loss: 134.6924\n",
      "Epoch 131/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 156.8099 - val_loss: 133.1621\n",
      "Epoch 132/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 154.9979 - val_loss: 133.1689\n",
      "Epoch 133/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 154.7198 - val_loss: 131.9237\n",
      "Epoch 134/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 152.9850 - val_loss: 130.7293\n",
      "Epoch 135/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 151.7062 - val_loss: 129.2655\n",
      "Epoch 136/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 150.5042 - val_loss: 128.1533\n",
      "Epoch 137/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 149.3469 - val_loss: 127.3457\n",
      "Epoch 138/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 148.2604 - val_loss: 125.5553\n",
      "Epoch 139/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 147.2066 - val_loss: 126.5865\n",
      "Epoch 140/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 146.0615 - val_loss: 123.8150\n",
      "Epoch 141/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 145.2177 - val_loss: 123.3127\n",
      "Epoch 142/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 144.5280 - val_loss: 122.8360\n",
      "Epoch 143/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 143.5889 - val_loss: 121.9228\n",
      "Epoch 144/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 142.8698 - val_loss: 121.9985\n",
      "Epoch 145/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 141.7088 - val_loss: 120.4162\n",
      "Epoch 146/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 140.8934 - val_loss: 120.3103\n",
      "Epoch 147/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 140.1204 - val_loss: 119.0889\n",
      "Epoch 148/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 139.2777 - val_loss: 118.7629\n",
      "Epoch 149/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 138.8533 - val_loss: 118.7437\n",
      "Epoch 150/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 137.9099 - val_loss: 117.4155\n",
      "Epoch 151/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 137.2938 - val_loss: 116.9746\n",
      "Epoch 152/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 136.6363 - val_loss: 116.3375\n",
      "Epoch 153/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 135.8989 - val_loss: 116.2742\n",
      "Epoch 154/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 135.2989 - val_loss: 116.4716\n",
      "Epoch 155/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 135.3010 - val_loss: 115.6659\n",
      "Epoch 156/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 134.2115 - val_loss: 115.4552\n",
      "Epoch 157/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 133.9122 - val_loss: 115.4985\n",
      "Epoch 158/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 133.2195 - val_loss: 114.3039\n",
      "Epoch 159/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 132.7789 - val_loss: 113.4370\n",
      "Epoch 160/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 132.5146 - val_loss: 113.3020\n",
      "Epoch 161/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 132.7807 - val_loss: 114.3711\n",
      "Epoch 162/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 131.8914 - val_loss: 112.9192\n",
      "Epoch 163/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 130.9289 - val_loss: 112.4869\n",
      "Epoch 164/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 130.6747 - val_loss: 112.0590\n",
      "Epoch 165/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 130.4806 - val_loss: 111.8979\n",
      "Epoch 166/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 129.5970 - val_loss: 111.8942\n",
      "Epoch 167/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 130.0153 - val_loss: 112.1749\n",
      "Epoch 168/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 128.8801 - val_loss: 111.0580\n",
      "Epoch 169/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 128.9857 - val_loss: 110.3806\n",
      "Epoch 170/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 128.2526 - val_loss: 110.6779\n",
      "Epoch 171/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 128.6130 - val_loss: 109.8551\n",
      "Epoch 172/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 127.7410 - val_loss: 110.0345\n",
      "Epoch 173/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 127.2588 - val_loss: 109.7600\n",
      "Epoch 174/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 127.3586 - val_loss: 109.8417\n",
      "Epoch 175/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 126.9794 - val_loss: 109.5404\n",
      "Epoch 176/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 126.6471 - val_loss: 109.1262\n",
      "Epoch 177/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 126.1229 - val_loss: 109.1694\n",
      "Epoch 178/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 126.1822 - val_loss: 109.2663\n",
      "Epoch 179/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 126.3283 - val_loss: 110.9321\n",
      "Epoch 180/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 125.8579 - val_loss: 108.4952\n",
      "Epoch 181/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 125.2247 - val_loss: 108.4610\n",
      "Epoch 182/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 125.5246 - val_loss: 108.4260\n",
      "Epoch 183/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 125.0540 - val_loss: 108.3902\n",
      "Epoch 184/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 124.5045 - val_loss: 108.5172\n",
      "Epoch 185/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 124.5692 - val_loss: 107.7232\n",
      "Epoch 186/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 124.5160 - val_loss: 107.1721\n",
      "Epoch 187/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 124.2100 - val_loss: 108.0161\n",
      "Epoch 188/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 123.6852 - val_loss: 107.7948\n",
      "Epoch 189/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 123.5027 - val_loss: 107.7696\n",
      "Epoch 190/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 123.3071 - val_loss: 107.0875\n",
      "Epoch 191/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 123.5304 - val_loss: 106.7988\n",
      "Epoch 192/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 123.4105 - val_loss: 107.0407\n",
      "Epoch 193/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 123.5167 - val_loss: 108.1934\n",
      "Epoch 194/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 123.0348 - val_loss: 106.2798\n",
      "Epoch 195/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 122.9372 - val_loss: 106.8096\n",
      "Epoch 196/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 122.2692 - val_loss: 106.2619\n",
      "Epoch 197/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 122.3403 - val_loss: 107.4182\n",
      "Epoch 198/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 122.8785 - val_loss: 106.8465\n",
      "Epoch 199/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 121.8500 - val_loss: 106.5458\n",
      "Epoch 200/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 122.4461 - val_loss: 107.3383\n",
      "Epoch 201/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 121.5141 - val_loss: 105.8902\n",
      "Epoch 202/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 121.5461 - val_loss: 106.1389\n",
      "Epoch 203/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 121.4553 - val_loss: 106.2128\n",
      "Epoch 204/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 121.0592 - val_loss: 105.6333\n",
      "Epoch 205/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 120.9265 - val_loss: 106.2551\n",
      "Epoch 206/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 120.9818 - val_loss: 105.3350\n",
      "Epoch 207/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 121.1557 - val_loss: 106.2273\n",
      "Epoch 208/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 121.2625 - val_loss: 105.8417\n",
      "Epoch 209/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 120.6516 - val_loss: 105.4251\n",
      "Epoch 210/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 121.0047 - val_loss: 104.7936\n",
      "Epoch 211/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 120.6651 - val_loss: 105.7403\n",
      "Epoch 212/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 120.3220 - val_loss: 105.2543\n",
      "Epoch 213/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 120.2120 - val_loss: 105.3108\n",
      "Epoch 214/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 119.9489 - val_loss: 104.8777\n",
      "Epoch 215/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 119.9327 - val_loss: 104.5209\n",
      "Epoch 216/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 120.6429 - val_loss: 104.5987\n",
      "Epoch 217/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 120.0695 - val_loss: 105.6051\n",
      "Epoch 218/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 119.6920 - val_loss: 104.0255\n",
      "Epoch 219/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 120.0156 - val_loss: 104.4306\n",
      "Epoch 220/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 119.5060 - val_loss: 104.3815\n",
      "Epoch 221/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 119.8815 - val_loss: 104.9174\n",
      "Epoch 222/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 119.2573 - val_loss: 104.2320\n",
      "Epoch 223/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 118.9391 - val_loss: 104.5682\n",
      "Epoch 224/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 119.0138 - val_loss: 104.5196\n",
      "Epoch 225/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 119.4449 - val_loss: 105.4751\n",
      "Epoch 226/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 119.2471 - val_loss: 103.9789\n",
      "Epoch 227/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 119.0493 - val_loss: 103.6938\n",
      "Epoch 228/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 119.1360 - val_loss: 104.3149\n",
      "Epoch 229/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 118.7673 - val_loss: 104.5629\n",
      "Epoch 230/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 119.1491 - val_loss: 103.1871\n",
      "Epoch 231/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 118.5955 - val_loss: 103.8997\n",
      "Epoch 232/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 118.4698 - val_loss: 103.3024\n",
      "Epoch 233/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 118.4511 - val_loss: 103.9121\n",
      "Epoch 234/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 118.4950 - val_loss: 104.0437\n",
      "Epoch 235/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 118.6406 - val_loss: 102.9869\n",
      "Epoch 236/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 118.1176 - val_loss: 104.0189\n",
      "Epoch 237/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 118.1831 - val_loss: 103.5415\n",
      "Epoch 238/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 117.9846 - val_loss: 103.6194\n",
      "Epoch 239/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 117.7552 - val_loss: 103.1249\n",
      "Epoch 240/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 117.7997 - val_loss: 103.2690\n",
      "Epoch 241/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 118.1712 - val_loss: 102.6010\n",
      "Epoch 242/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 118.0902 - val_loss: 104.3677\n",
      "Epoch 243/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 117.8304 - val_loss: 103.7388\n",
      "Epoch 244/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 117.4920 - val_loss: 102.4635\n",
      "Epoch 245/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 117.7617 - val_loss: 103.4643\n",
      "Epoch 246/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 118.0864 - val_loss: 103.0182\n",
      "Epoch 247/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 117.6880 - val_loss: 102.7826\n",
      "Epoch 248/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 118.3333 - val_loss: 103.8947\n",
      "Epoch 249/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 117.0985 - val_loss: 102.5499\n",
      "Epoch 250/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 117.1464 - val_loss: 102.4900\n",
      "Epoch 251/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 118.0362 - val_loss: 102.3672\n",
      "Epoch 252/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 117.2496 - val_loss: 102.9992\n",
      "Epoch 253/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 117.3106 - val_loss: 102.1087\n",
      "Epoch 254/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 117.1620 - val_loss: 103.5276\n",
      "Epoch 255/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 117.4481 - val_loss: 101.9333\n",
      "Epoch 256/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 116.9230 - val_loss: 103.2600\n",
      "Epoch 257/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 117.6943 - val_loss: 102.0471\n",
      "Epoch 258/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 116.8528 - val_loss: 102.7102\n",
      "Epoch 259/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 116.9918 - val_loss: 102.2003\n",
      "Epoch 260/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 116.6425 - val_loss: 102.1602\n",
      "Epoch 261/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 116.6723 - val_loss: 102.1643\n",
      "Epoch 262/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 116.5839 - val_loss: 102.2544\n",
      "Epoch 263/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 116.6241 - val_loss: 101.7470\n",
      "Epoch 264/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 116.3600 - val_loss: 102.1879\n",
      "Epoch 265/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 116.3667 - val_loss: 102.2010\n",
      "Epoch 266/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 116.2976 - val_loss: 102.1719\n",
      "Epoch 267/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 116.2864 - val_loss: 101.5744\n",
      "Epoch 268/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 116.0610 - val_loss: 102.2217\n",
      "Epoch 269/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 117.1653 - val_loss: 101.5052\n",
      "Epoch 270/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 117.2081 - val_loss: 101.6709\n",
      "Epoch 271/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 116.1544 - val_loss: 101.5684\n",
      "Epoch 272/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 116.0331 - val_loss: 102.1202\n",
      "Epoch 273/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 116.1349 - val_loss: 101.9654\n",
      "Epoch 274/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 116.5052 - val_loss: 102.8293\n",
      "Epoch 275/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 115.9697 - val_loss: 101.8682\n",
      "Epoch 276/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 115.8399 - val_loss: 100.9923\n",
      "Epoch 277/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 116.0012 - val_loss: 101.9721\n",
      "Epoch 278/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 116.0089 - val_loss: 101.0790\n",
      "Epoch 279/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 116.4861 - val_loss: 102.6038\n",
      "Epoch 280/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 115.7490 - val_loss: 101.1203\n",
      "Epoch 281/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 115.9720 - val_loss: 101.4604\n",
      "Epoch 282/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 116.4540 - val_loss: 102.5642\n",
      "Epoch 283/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 116.5816 - val_loss: 101.3162\n",
      "Epoch 284/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 115.9647 - val_loss: 101.8295\n",
      "Epoch 285/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 115.6456 - val_loss: 101.1279\n",
      "Epoch 286/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 115.9024 - val_loss: 101.6198\n",
      "Epoch 287/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 116.7387 - val_loss: 100.8985\n",
      "Epoch 288/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 115.5985 - val_loss: 101.1414\n",
      "Epoch 289/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 115.3812 - val_loss: 100.6656\n",
      "Epoch 290/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 115.3487 - val_loss: 101.6002\n",
      "Epoch 291/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 115.4563 - val_loss: 101.5008\n",
      "Epoch 292/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 115.2877 - val_loss: 101.4558\n",
      "Epoch 293/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 115.4949 - val_loss: 101.6680\n",
      "Epoch 294/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 115.3815 - val_loss: 100.7464\n",
      "Epoch 295/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 115.2395 - val_loss: 102.3954\n",
      "Epoch 296/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 115.8353 - val_loss: 101.5303\n",
      "Epoch 297/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 115.1060 - val_loss: 101.1660\n",
      "Epoch 298/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 115.3737 - val_loss: 101.3848\n",
      "Epoch 299/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 115.3163 - val_loss: 101.0748\n",
      "Epoch 300/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 115.0353 - val_loss: 100.9760\n",
      "Epoch 301/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 115.0312 - val_loss: 100.4516\n",
      "Epoch 302/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 115.0743 - val_loss: 100.5645\n",
      "Epoch 303/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 115.3361 - val_loss: 102.3040\n",
      "Epoch 304/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.8204 - val_loss: 100.3712\n",
      "Epoch 305/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 115.1499 - val_loss: 100.5482\n",
      "Epoch 306/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 115.1739 - val_loss: 100.7717\n",
      "Epoch 307/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 115.2171 - val_loss: 100.9807\n",
      "Epoch 308/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 114.8421 - val_loss: 101.3234\n",
      "Epoch 309/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 114.7284 - val_loss: 100.3350\n",
      "Epoch 310/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 114.7156 - val_loss: 100.6367\n",
      "Epoch 311/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.7306 - val_loss: 100.7069\n",
      "Epoch 312/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.5781 - val_loss: 100.4289\n",
      "Epoch 313/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.8876 - val_loss: 101.5738\n",
      "Epoch 314/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.6878 - val_loss: 100.0061\n",
      "Epoch 315/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 115.0990 - val_loss: 100.8815\n",
      "Epoch 316/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 114.7312 - val_loss: 100.7075\n",
      "Epoch 317/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.7167 - val_loss: 100.2840\n",
      "Epoch 318/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 114.3044 - val_loss: 101.0329\n",
      "Epoch 319/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 114.9416 - val_loss: 100.7450\n",
      "Epoch 320/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.6199 - val_loss: 100.6966\n",
      "Epoch 321/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 115.0207 - val_loss: 99.9565\n",
      "Epoch 322/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.5509 - val_loss: 100.4779\n",
      "Epoch 323/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 114.6339 - val_loss: 100.7540\n",
      "Epoch 324/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.3307 - val_loss: 100.3703\n",
      "Epoch 325/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.4846 - val_loss: 100.1578\n",
      "Epoch 326/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.3664 - val_loss: 100.2816\n",
      "Epoch 327/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 114.4228 - val_loss: 99.8564\n",
      "Epoch 328/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.1532 - val_loss: 100.7777\n",
      "Epoch 329/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.3676 - val_loss: 100.0561\n",
      "Epoch 330/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.5411 - val_loss: 100.0064\n",
      "Epoch 331/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.2698 - val_loss: 100.2912\n",
      "Epoch 332/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.1371 - val_loss: 99.9901\n",
      "Epoch 333/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.4305 - val_loss: 99.6415\n",
      "Epoch 334/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 115.4575 - val_loss: 100.5606\n",
      "Epoch 335/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.2052 - val_loss: 99.8371\n",
      "Epoch 336/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 115.0812 - val_loss: 100.2790\n",
      "Epoch 337/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.1928 - val_loss: 100.0442\n",
      "Epoch 338/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 114.2747 - val_loss: 101.1401\n",
      "Epoch 339/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.2343 - val_loss: 99.5943\n",
      "Epoch 340/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.1702 - val_loss: 100.5458\n",
      "Epoch 341/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.2580 - val_loss: 100.7362\n",
      "Epoch 342/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 114.3216 - val_loss: 99.7442\n",
      "Epoch 343/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 114.7078 - val_loss: 100.7088\n",
      "Epoch 344/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.3688 - val_loss: 100.5320\n",
      "Epoch 345/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.6140 - val_loss: 99.4197\n",
      "Epoch 346/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.1138 - val_loss: 100.5385\n",
      "Epoch 347/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.0411 - val_loss: 99.9063\n",
      "Epoch 348/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.1618 - val_loss: 99.5641\n",
      "Epoch 349/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 114.0533 - val_loss: 99.9930\n",
      "Epoch 350/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.0109 - val_loss: 99.8015\n",
      "Epoch 351/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.7328 - val_loss: 99.7007\n",
      "Epoch 352/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.6898 - val_loss: 99.9331\n",
      "Epoch 353/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.9781 - val_loss: 99.4223\n",
      "Epoch 354/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.7601 - val_loss: 99.8498\n",
      "Epoch 355/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.3143 - val_loss: 99.5094\n",
      "Epoch 356/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 114.2180 - val_loss: 102.4937\n",
      "Epoch 357/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.7199 - val_loss: 99.2628\n",
      "Epoch 358/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.7577 - val_loss: 99.8710\n",
      "Epoch 359/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.9906 - val_loss: 100.3104\n",
      "Epoch 360/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 114.0564 - val_loss: 99.1852\n",
      "Epoch 361/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 114.4172 - val_loss: 100.0396\n",
      "Epoch 362/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 114.5597 - val_loss: 99.4099\n",
      "Epoch 363/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.6387 - val_loss: 99.4975\n",
      "Epoch 364/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.7781 - val_loss: 99.3573\n",
      "Epoch 365/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 113.8085 - val_loss: 101.4463\n",
      "Epoch 366/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 114.5331 - val_loss: 99.9781\n",
      "Epoch 367/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.9267 - val_loss: 99.4714\n",
      "Epoch 368/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.2511 - val_loss: 99.5150\n",
      "Epoch 369/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.9031 - val_loss: 99.4004\n",
      "Epoch 370/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.4079 - val_loss: 99.8619\n",
      "Epoch 371/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.6975 - val_loss: 99.6415\n",
      "Epoch 372/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.5184 - val_loss: 99.4889\n",
      "Epoch 373/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.9260 - val_loss: 99.1324\n",
      "Epoch 374/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.9270 - val_loss: 99.9169\n",
      "Epoch 375/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.6587 - val_loss: 100.0868\n",
      "Epoch 376/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.4975 - val_loss: 100.9185\n",
      "Epoch 377/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 113.4816 - val_loss: 99.2309\n",
      "Epoch 378/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 113.4695 - val_loss: 99.8219\n",
      "Epoch 379/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.6237 - val_loss: 99.7723\n",
      "Epoch 380/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.5001 - val_loss: 99.7439\n",
      "Epoch 381/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.5263 - val_loss: 99.7768\n",
      "Epoch 382/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.7074 - val_loss: 99.3975\n",
      "Epoch 383/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.1702 - val_loss: 99.2803\n",
      "Epoch 384/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.4516 - val_loss: 100.1865\n",
      "Epoch 385/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.4682 - val_loss: 99.5169\n",
      "Epoch 386/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.5481 - val_loss: 99.9566\n",
      "Epoch 387/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.7085 - val_loss: 99.3744\n",
      "Epoch 388/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.3286 - val_loss: 100.1469\n",
      "Epoch 389/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.3540 - val_loss: 99.7627\n",
      "Epoch 390/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.3345 - val_loss: 99.2112\n",
      "Epoch 391/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.4299 - val_loss: 99.5650\n",
      "Epoch 392/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.2787 - val_loss: 99.8298\n",
      "Epoch 393/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 113.1782 - val_loss: 99.3755\n",
      "Epoch 394/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 113.5283 - val_loss: 99.0631\n",
      "Epoch 395/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.5314 - val_loss: 99.4822\n",
      "Epoch 396/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.7345 - val_loss: 100.6493\n",
      "Epoch 397/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.6899 - val_loss: 99.4914\n",
      "Epoch 398/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.3498 - val_loss: 100.3939\n",
      "Epoch 399/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.5093 - val_loss: 100.1034\n",
      "Epoch 400/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.3209 - val_loss: 98.8965\n",
      "Epoch 401/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.6028 - val_loss: 100.7762\n",
      "Epoch 402/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.5426 - val_loss: 99.7533\n",
      "Epoch 403/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.3699 - val_loss: 99.1374\n",
      "Epoch 404/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0982 - val_loss: 100.3678\n",
      "Epoch 405/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.7850 - val_loss: 99.1125\n",
      "Epoch 406/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 114.2767 - val_loss: 99.1607\n",
      "Epoch 407/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0527 - val_loss: 99.5258\n",
      "Epoch 408/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.1050 - val_loss: 100.1213\n",
      "Epoch 409/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.6722 - val_loss: 99.9698\n",
      "Epoch 410/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.6136 - val_loss: 99.3702\n",
      "Epoch 411/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0843 - val_loss: 99.9835\n",
      "Epoch 412/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.2726 - val_loss: 99.1603\n",
      "Epoch 413/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 113.1217 - val_loss: 98.9938\n",
      "Epoch 414/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.1960 - val_loss: 99.6656\n",
      "Epoch 415/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.6500 - val_loss: 100.6491\n",
      "Epoch 416/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.8392 - val_loss: 99.4694\n",
      "Epoch 417/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.4471 - val_loss: 99.1493\n",
      "Epoch 418/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.0238 - val_loss: 99.4364\n",
      "Epoch 419/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.2376 - val_loss: 99.3195\n",
      "Epoch 420/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.1274 - val_loss: 99.2726\n",
      "Epoch 421/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.4827 - val_loss: 98.7591\n",
      "Epoch 422/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.9966 - val_loss: 100.5137\n",
      "Epoch 423/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.6475 - val_loss: 100.1876\n",
      "Epoch 424/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.9338 - val_loss: 99.0903\n",
      "Epoch 425/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.0271 - val_loss: 99.3277\n",
      "Epoch 426/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.6248 - val_loss: 98.5637\n",
      "Epoch 427/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.2411 - val_loss: 99.5927\n",
      "Epoch 428/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.0157 - val_loss: 98.6498\n",
      "Epoch 429/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.6100 - val_loss: 99.4241\n",
      "Epoch 430/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 113.0544 - val_loss: 99.0174\n",
      "Epoch 431/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.2664 - val_loss: 99.2282\n",
      "Epoch 432/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0394 - val_loss: 99.4831\n",
      "Epoch 433/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.3970 - val_loss: 99.0119\n",
      "Epoch 434/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.3270 - val_loss: 99.0175\n",
      "Epoch 435/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.2981 - val_loss: 98.5947\n",
      "Epoch 436/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.9319 - val_loss: 99.8827\n",
      "Epoch 437/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.2406 - val_loss: 99.4271\n",
      "Epoch 438/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.1379 - val_loss: 98.9259\n",
      "Epoch 439/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9643 - val_loss: 100.1167\n",
      "Epoch 440/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.0685 - val_loss: 98.9624\n",
      "Epoch 441/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.4829 - val_loss: 98.9683\n",
      "Epoch 442/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.2809 - val_loss: 99.9696\n",
      "Epoch 443/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.2161 - val_loss: 98.6720\n",
      "Epoch 444/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.1869 - val_loss: 98.7475\n",
      "Epoch 445/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0718 - val_loss: 99.3835\n",
      "Epoch 446/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.1680 - val_loss: 99.6008\n",
      "Epoch 447/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8039 - val_loss: 98.8761\n",
      "Epoch 448/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.2105 - val_loss: 99.6871\n",
      "Epoch 449/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8200 - val_loss: 98.7990\n",
      "Epoch 450/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.3504 - val_loss: 99.3455\n",
      "Epoch 451/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.2652 - val_loss: 98.6082\n",
      "Epoch 452/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.4119 - val_loss: 99.8122\n",
      "Epoch 453/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 114.4561 - val_loss: 101.2520\n",
      "Epoch 454/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.8932 - val_loss: 98.5654\n",
      "Epoch 455/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.3638 - val_loss: 99.2083\n",
      "Epoch 456/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.0120 - val_loss: 100.2135\n",
      "Epoch 457/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.7961 - val_loss: 98.9651\n",
      "Epoch 458/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.3191 - val_loss: 98.8921\n",
      "Epoch 459/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.3641 - val_loss: 99.5605\n",
      "Epoch 460/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.8118 - val_loss: 98.5715\n",
      "Epoch 461/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 114.9486 - val_loss: 99.7812\n",
      "Epoch 462/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.8997 - val_loss: 99.2347\n",
      "Epoch 463/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8726 - val_loss: 99.6903\n",
      "Epoch 464/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.0563 - val_loss: 99.5187\n",
      "Epoch 465/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.2024 - val_loss: 99.2316\n",
      "Epoch 466/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.1700 - val_loss: 98.4311\n",
      "Epoch 467/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.2894 - val_loss: 99.0721\n",
      "Epoch 468/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0442 - val_loss: 99.5390\n",
      "Epoch 469/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8807 - val_loss: 98.9747\n",
      "Epoch 470/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.2582 - val_loss: 98.9740\n",
      "Epoch 471/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.9797 - val_loss: 98.5053\n",
      "Epoch 472/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7566 - val_loss: 99.6892\n",
      "Epoch 473/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.8942 - val_loss: 99.1313\n",
      "Epoch 474/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.0368 - val_loss: 99.4016\n",
      "Epoch 475/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9123 - val_loss: 98.5244\n",
      "Epoch 476/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.3749 - val_loss: 99.7383\n",
      "Epoch 477/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.7762 - val_loss: 98.3896\n",
      "Epoch 478/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.1779 - val_loss: 98.5380\n",
      "Epoch 479/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.8398 - val_loss: 99.3342\n",
      "Epoch 480/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8765 - val_loss: 99.0319\n",
      "Epoch 481/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.1965 - val_loss: 100.2606\n",
      "Epoch 482/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.1052 - val_loss: 99.2777\n",
      "Epoch 483/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.8582 - val_loss: 98.9130\n",
      "Epoch 484/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7536 - val_loss: 98.9886\n",
      "Epoch 485/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.4041 - val_loss: 98.9967\n",
      "Epoch 486/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.3873 - val_loss: 98.8468\n",
      "Epoch 487/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.1241 - val_loss: 99.7126\n",
      "Epoch 488/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6366 - val_loss: 98.6636\n",
      "Epoch 489/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6659 - val_loss: 99.2828\n",
      "Epoch 490/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0405 - val_loss: 98.4957\n",
      "Epoch 491/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.7796 - val_loss: 99.7096\n",
      "Epoch 492/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.9706 - val_loss: 99.1826\n",
      "Epoch 493/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.0166 - val_loss: 98.3680\n",
      "Epoch 494/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.8612 - val_loss: 99.2691\n",
      "Epoch 495/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8268 - val_loss: 98.6607\n",
      "Epoch 496/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9480 - val_loss: 98.7278\n",
      "Epoch 497/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.1135 - val_loss: 98.6955\n",
      "Epoch 498/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.8895 - val_loss: 99.4632\n",
      "Epoch 499/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0371 - val_loss: 98.4101\n",
      "Epoch 500/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.8916 - val_loss: 99.4719\n",
      "Epoch 501/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.7538 - val_loss: 99.1722\n",
      "Epoch 502/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.6680 - val_loss: 99.6173\n",
      "Epoch 503/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.3142 - val_loss: 98.6652\n",
      "Epoch 504/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.8952 - val_loss: 98.8116\n",
      "Epoch 505/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6459 - val_loss: 98.7720\n",
      "Epoch 506/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7787 - val_loss: 98.6642\n",
      "Epoch 507/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.9510 - val_loss: 99.4239\n",
      "Epoch 508/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.0085 - val_loss: 99.0141\n",
      "Epoch 509/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.1965 - val_loss: 99.1360\n",
      "Epoch 510/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.1348 - val_loss: 99.5047\n",
      "Epoch 511/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.1486 - val_loss: 99.4388\n",
      "Epoch 512/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.7251 - val_loss: 98.8304\n",
      "Epoch 513/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8203 - val_loss: 98.7890\n",
      "Epoch 514/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6386 - val_loss: 99.2356\n",
      "Epoch 515/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.9318 - val_loss: 98.5609\n",
      "Epoch 516/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.9094 - val_loss: 99.4271\n",
      "Epoch 517/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.2246 - val_loss: 98.8758\n",
      "Epoch 518/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.1298 - val_loss: 98.6001\n",
      "Epoch 519/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 112.9041 - val_loss: 99.5413\n",
      "Epoch 520/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 112.7084 - val_loss: 99.4572\n",
      "Epoch 521/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.0708 - val_loss: 98.9401\n",
      "Epoch 522/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 112.9333 - val_loss: 99.0930\n",
      "Epoch 523/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 112.6351 - val_loss: 98.7042\n",
      "Epoch 524/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 112.9035 - val_loss: 99.9115\n",
      "Epoch 525/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.5156 - val_loss: 99.8861\n",
      "Epoch 526/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.6915 - val_loss: 98.7347\n",
      "Epoch 527/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.1405 - val_loss: 99.1002\n",
      "Epoch 528/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0095 - val_loss: 98.9727\n",
      "Epoch 529/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.0647 - val_loss: 98.6562\n",
      "Epoch 530/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8289 - val_loss: 99.6218\n",
      "Epoch 531/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.8398 - val_loss: 99.1277\n",
      "Epoch 532/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.7102 - val_loss: 98.6900\n",
      "Epoch 533/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.5921 - val_loss: 98.4709\n",
      "Epoch 534/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.2962 - val_loss: 98.5800\n",
      "Epoch 535/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.1386 - val_loss: 99.7341\n",
      "Epoch 536/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7741 - val_loss: 99.1158\n",
      "Epoch 537/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.8294 - val_loss: 98.6746\n",
      "Epoch 538/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8982 - val_loss: 100.0392\n",
      "Epoch 539/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.5495 - val_loss: 98.6362\n",
      "Epoch 540/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 114.7237 - val_loss: 99.5826\n",
      "Epoch 541/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.5467 - val_loss: 98.5734\n",
      "Epoch 542/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.3439 - val_loss: 100.2921\n",
      "Epoch 543/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.7305 - val_loss: 98.6499\n",
      "Epoch 544/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.7350 - val_loss: 99.4745\n",
      "Epoch 545/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.5969 - val_loss: 98.7750\n",
      "Epoch 546/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.9790 - val_loss: 99.8080\n",
      "Epoch 547/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.7317 - val_loss: 98.2743\n",
      "Epoch 548/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.3719 - val_loss: 100.1722\n",
      "Epoch 549/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9456 - val_loss: 98.7152\n",
      "Epoch 550/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.6618 - val_loss: 100.5789\n",
      "Epoch 551/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.5552 - val_loss: 98.2306\n",
      "Epoch 552/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 112.6160 - val_loss: 99.4701\n",
      "Epoch 553/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6134 - val_loss: 98.5043\n",
      "Epoch 554/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8076 - val_loss: 99.9110\n",
      "Epoch 555/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0087 - val_loss: 98.8928\n",
      "Epoch 556/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8139 - val_loss: 98.7798\n",
      "Epoch 557/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.2690 - val_loss: 98.2500\n",
      "Epoch 558/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.2177 - val_loss: 98.6463\n",
      "Epoch 559/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.3145 - val_loss: 98.7278\n",
      "Epoch 560/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9259 - val_loss: 99.2642\n",
      "Epoch 561/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.9171 - val_loss: 98.5434\n",
      "Epoch 562/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.4901 - val_loss: 99.1174\n",
      "Epoch 563/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5201 - val_loss: 98.8156\n",
      "Epoch 564/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.3008 - val_loss: 98.2461\n",
      "Epoch 565/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7701 - val_loss: 99.2245\n",
      "Epoch 566/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.2725 - val_loss: 98.1989\n",
      "Epoch 567/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 114.2771 - val_loss: 98.3061\n",
      "Epoch 568/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 113.1676 - val_loss: 99.5380\n",
      "Epoch 569/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.2580 - val_loss: 98.4101\n",
      "Epoch 570/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 113.0845 - val_loss: 99.6825\n",
      "Epoch 571/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.7051 - val_loss: 98.4172\n",
      "Epoch 572/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.4737 - val_loss: 99.1321\n",
      "Epoch 573/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.9548 - val_loss: 98.2769\n",
      "Epoch 574/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.1315 - val_loss: 100.3132\n",
      "Epoch 575/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.1058 - val_loss: 98.9385\n",
      "Epoch 576/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.9158 - val_loss: 99.0490\n",
      "Epoch 577/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 112.4813 - val_loss: 98.3314\n",
      "Epoch 578/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.9626 - val_loss: 99.9262\n",
      "Epoch 579/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8011 - val_loss: 98.5198\n",
      "Epoch 580/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.6237 - val_loss: 98.9879\n",
      "Epoch 581/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.5926 - val_loss: 98.3158\n",
      "Epoch 582/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 112.5324 - val_loss: 99.7286\n",
      "Epoch 583/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.7935 - val_loss: 99.7966\n",
      "Epoch 584/1000\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 113.1031 - val_loss: 98.2277\n",
      "Epoch 585/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 112.6496 - val_loss: 99.1923\n",
      "Epoch 586/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 112.7945 - val_loss: 99.1007\n",
      "Epoch 587/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.3513 - val_loss: 100.3320\n",
      "Epoch 588/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.1004 - val_loss: 99.4542\n",
      "Epoch 589/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8790 - val_loss: 99.3529\n",
      "Epoch 590/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6139 - val_loss: 98.9258\n",
      "Epoch 591/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6345 - val_loss: 99.0531\n",
      "Epoch 592/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.0002 - val_loss: 99.6331\n",
      "Epoch 593/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 113.0984 - val_loss: 98.5732\n",
      "Epoch 594/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.7036 - val_loss: 98.2271\n",
      "Epoch 595/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9290 - val_loss: 98.6996\n",
      "Epoch 596/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.4754 - val_loss: 99.0580\n",
      "Epoch 597/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 113.0821 - val_loss: 99.4026\n",
      "Epoch 598/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.5421 - val_loss: 98.7777\n",
      "Epoch 599/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5233 - val_loss: 98.6928\n",
      "Epoch 600/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.6393 - val_loss: 100.0159\n",
      "Epoch 601/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0447 - val_loss: 98.7381\n",
      "Epoch 602/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7717 - val_loss: 99.1384\n",
      "Epoch 603/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.8359 - val_loss: 99.2025\n",
      "Epoch 604/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.1654 - val_loss: 100.3950\n",
      "Epoch 605/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.1856 - val_loss: 98.5581\n",
      "Epoch 606/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5809 - val_loss: 99.3249\n",
      "Epoch 607/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.9040 - val_loss: 99.8450\n",
      "Epoch 608/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.1059 - val_loss: 98.2342\n",
      "Epoch 609/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5825 - val_loss: 99.5775\n",
      "Epoch 610/1000\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 113.0318 - val_loss: 98.2897\n",
      "Epoch 611/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 112.6657 - val_loss: 98.7072\n",
      "Epoch 612/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.8540 - val_loss: 99.5516\n",
      "Epoch 613/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.8748 - val_loss: 99.6134\n",
      "Epoch 614/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 113.5575 - val_loss: 98.3569\n",
      "Epoch 615/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 112.3518 - val_loss: 100.0951\n",
      "Epoch 616/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 113.0658 - val_loss: 98.7709\n",
      "Epoch 617/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7983 - val_loss: 99.2045\n",
      "Epoch 618/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7933 - val_loss: 99.1580\n",
      "Epoch 619/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6675 - val_loss: 98.9817\n",
      "Epoch 620/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.8144 - val_loss: 98.4122\n",
      "Epoch 621/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.9803 - val_loss: 99.8063\n",
      "Epoch 622/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8487 - val_loss: 99.4080\n",
      "Epoch 623/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.9465 - val_loss: 98.7825\n",
      "Epoch 624/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 112.8741 - val_loss: 99.3504\n",
      "Epoch 625/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7135 - val_loss: 98.2065\n",
      "Epoch 626/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.5773 - val_loss: 99.6124\n",
      "Epoch 627/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.1120 - val_loss: 100.0794\n",
      "Epoch 628/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.4597 - val_loss: 99.5711\n",
      "Epoch 629/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.9539 - val_loss: 98.4172\n",
      "Epoch 630/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.3385 - val_loss: 99.4506\n",
      "Epoch 631/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.1548 - val_loss: 99.0509\n",
      "Epoch 632/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.5036 - val_loss: 99.0312\n",
      "Epoch 633/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9172 - val_loss: 98.5736\n",
      "Epoch 634/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.5695 - val_loss: 98.8743\n",
      "Epoch 635/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7496 - val_loss: 98.7676\n",
      "Epoch 636/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 114.4236 - val_loss: 100.9835\n",
      "Epoch 637/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.3274 - val_loss: 98.3002\n",
      "Epoch 638/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.8218 - val_loss: 98.7030\n",
      "Epoch 639/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 112.6284 - val_loss: 99.0557\n",
      "Epoch 640/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.8694 - val_loss: 99.2954\n",
      "Epoch 641/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.8006 - val_loss: 98.2568\n",
      "Epoch 642/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5584 - val_loss: 98.8492\n",
      "Epoch 643/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8467 - val_loss: 98.6587\n",
      "Epoch 644/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.3123 - val_loss: 99.0747\n",
      "Epoch 645/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.7354 - val_loss: 99.2995\n",
      "Epoch 646/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7052 - val_loss: 98.3445\n",
      "Epoch 647/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.0651 - val_loss: 100.4095\n",
      "Epoch 648/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.5586 - val_loss: 98.4910\n",
      "Epoch 649/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5217 - val_loss: 99.5526\n",
      "Epoch 650/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.5050 - val_loss: 98.2116\n",
      "Epoch 651/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.4559 - val_loss: 98.7205\n",
      "Epoch 652/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6529 - val_loss: 99.1293\n",
      "Epoch 653/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9276 - val_loss: 99.0525\n",
      "Epoch 654/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 112.6742 - val_loss: 98.9587\n",
      "Epoch 655/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.5818 - val_loss: 99.2938\n",
      "Epoch 656/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0633 - val_loss: 99.0083\n",
      "Epoch 657/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5141 - val_loss: 98.6633\n",
      "Epoch 658/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.5782 - val_loss: 98.9606\n",
      "Epoch 659/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6022 - val_loss: 98.3868\n",
      "Epoch 660/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 112.7575 - val_loss: 98.3311\n",
      "Epoch 661/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.5934 - val_loss: 98.7586\n",
      "Epoch 662/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5760 - val_loss: 99.7153\n",
      "Epoch 663/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8470 - val_loss: 98.1742\n",
      "Epoch 664/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.7486 - val_loss: 98.5845\n",
      "Epoch 665/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.5268 - val_loss: 98.6839\n",
      "Epoch 666/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6420 - val_loss: 98.2226\n",
      "Epoch 667/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6314 - val_loss: 99.7175\n",
      "Epoch 668/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.1106 - val_loss: 98.1824\n",
      "Epoch 669/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8412 - val_loss: 99.4330\n",
      "Epoch 670/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9251 - val_loss: 98.6275\n",
      "Epoch 671/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.7515 - val_loss: 101.0508\n",
      "Epoch 672/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.8626 - val_loss: 98.1517\n",
      "Epoch 673/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.7668 - val_loss: 98.3837\n",
      "Epoch 674/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.7829 - val_loss: 98.6683\n",
      "Epoch 675/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.4787 - val_loss: 99.4193\n",
      "Epoch 676/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.8021 - val_loss: 98.5637\n",
      "Epoch 677/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.5096 - val_loss: 99.2542\n",
      "Epoch 678/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.7683 - val_loss: 98.5124\n",
      "Epoch 679/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9793 - val_loss: 98.6260\n",
      "Epoch 680/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.2337 - val_loss: 98.9219\n",
      "Epoch 681/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9662 - val_loss: 100.2336\n",
      "Epoch 682/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6402 - val_loss: 98.8912\n",
      "Epoch 683/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.8153 - val_loss: 100.8164\n",
      "Epoch 684/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 113.4903 - val_loss: 98.1550\n",
      "Epoch 685/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.8765 - val_loss: 98.8961\n",
      "Epoch 686/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5244 - val_loss: 98.7290\n",
      "Epoch 687/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6723 - val_loss: 98.3416\n",
      "Epoch 688/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 115.0780 - val_loss: 100.2880\n",
      "Epoch 689/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.7312 - val_loss: 98.4624\n",
      "Epoch 690/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.3558 - val_loss: 99.3820\n",
      "Epoch 691/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6111 - val_loss: 98.6698\n",
      "Epoch 692/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9736 - val_loss: 99.0396\n",
      "Epoch 693/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.8874 - val_loss: 98.1432\n",
      "Epoch 694/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.0783 - val_loss: 99.2100\n",
      "Epoch 695/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.4214 - val_loss: 98.5090\n",
      "Epoch 696/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.7833 - val_loss: 98.5449\n",
      "Epoch 697/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.5779 - val_loss: 99.1156\n",
      "Epoch 698/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8051 - val_loss: 98.5795\n",
      "Epoch 699/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5230 - val_loss: 100.1785\n",
      "Epoch 700/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.4463 - val_loss: 98.2513\n",
      "Epoch 701/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6534 - val_loss: 99.0278\n",
      "Epoch 702/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6478 - val_loss: 98.2518\n",
      "Epoch 703/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7188 - val_loss: 98.7436\n",
      "Epoch 704/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5781 - val_loss: 98.8884\n",
      "Epoch 705/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8041 - val_loss: 99.6507\n",
      "Epoch 706/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.4813 - val_loss: 98.6662\n",
      "Epoch 707/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0237 - val_loss: 98.3383\n",
      "Epoch 708/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.6381 - val_loss: 99.9824\n",
      "Epoch 709/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9829 - val_loss: 98.2392\n",
      "Epoch 710/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 112.5200 - val_loss: 99.0535\n",
      "Epoch 711/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.8498 - val_loss: 99.0315\n",
      "Epoch 712/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6602 - val_loss: 98.4732\n",
      "Epoch 713/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.0415 - val_loss: 98.9440\n",
      "Epoch 714/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7807 - val_loss: 98.7135\n",
      "Epoch 715/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6360 - val_loss: 99.8289\n",
      "Epoch 716/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5532 - val_loss: 98.3621\n",
      "Epoch 717/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.5557 - val_loss: 99.6922\n",
      "Epoch 718/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8600 - val_loss: 98.6630\n",
      "Epoch 719/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0241 - val_loss: 98.5195\n",
      "Epoch 720/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.3384 - val_loss: 100.9210\n",
      "Epoch 721/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.7269 - val_loss: 98.2059\n",
      "Epoch 722/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.8647 - val_loss: 99.2101\n",
      "Epoch 723/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.7639 - val_loss: 98.3787\n",
      "Epoch 724/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7288 - val_loss: 98.3489\n",
      "Epoch 725/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6068 - val_loss: 98.8204\n",
      "Epoch 726/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.5621 - val_loss: 98.4845\n",
      "Epoch 727/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0418 - val_loss: 98.4302\n",
      "Epoch 728/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.9073 - val_loss: 100.7726\n",
      "Epoch 729/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.2008 - val_loss: 98.1076\n",
      "Epoch 730/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.2699 - val_loss: 98.4925\n",
      "Epoch 731/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.7853 - val_loss: 98.5018\n",
      "Epoch 732/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6805 - val_loss: 98.6195\n",
      "Epoch 733/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.7427 - val_loss: 99.6859\n",
      "Epoch 734/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6646 - val_loss: 98.9026\n",
      "Epoch 735/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.9200 - val_loss: 98.2052\n",
      "Epoch 736/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.4953 - val_loss: 98.7946\n",
      "Epoch 737/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.5147 - val_loss: 98.6703\n",
      "Epoch 738/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.7967 - val_loss: 101.2835\n",
      "Epoch 739/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9755 - val_loss: 98.2824\n",
      "Epoch 740/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.8517 - val_loss: 98.7596\n",
      "Epoch 741/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.5360 - val_loss: 99.8767\n",
      "Epoch 742/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7667 - val_loss: 98.0928\n",
      "Epoch 743/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.0747 - val_loss: 98.8062\n",
      "Epoch 744/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5132 - val_loss: 98.6196\n",
      "Epoch 745/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.2015 - val_loss: 100.2878\n",
      "Epoch 746/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0468 - val_loss: 98.4974\n",
      "Epoch 747/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.8979 - val_loss: 98.9241\n",
      "Epoch 748/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.6400 - val_loss: 98.4745\n",
      "Epoch 749/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.8041 - val_loss: 98.8074\n",
      "Epoch 750/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9448 - val_loss: 98.1686\n",
      "Epoch 751/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.7797 - val_loss: 101.6901\n",
      "Epoch 752/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 114.3038 - val_loss: 98.4103\n",
      "Epoch 753/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5398 - val_loss: 98.6534\n",
      "Epoch 754/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6548 - val_loss: 99.1148\n",
      "Epoch 755/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6829 - val_loss: 98.8211\n",
      "Epoch 756/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6888 - val_loss: 98.7167\n",
      "Epoch 757/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7484 - val_loss: 99.4119\n",
      "Epoch 758/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 112.5848 - val_loss: 98.7549\n",
      "Epoch 759/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8906 - val_loss: 99.2130\n",
      "Epoch 760/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8076 - val_loss: 99.7484\n",
      "Epoch 761/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.5487 - val_loss: 98.0243\n",
      "Epoch 762/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 114.1441 - val_loss: 100.3415\n",
      "Epoch 763/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.2357 - val_loss: 98.0063\n",
      "Epoch 764/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.2599 - val_loss: 99.3652\n",
      "Epoch 765/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.8656 - val_loss: 98.6865\n",
      "Epoch 766/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.0130 - val_loss: 98.1635\n",
      "Epoch 767/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.8185 - val_loss: 99.3354\n",
      "Epoch 768/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 113.2499 - val_loss: 99.9727\n",
      "Epoch 769/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.8216 - val_loss: 98.2457\n",
      "Epoch 770/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.1136 - val_loss: 99.0814\n",
      "Epoch 771/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.4902 - val_loss: 98.5621\n",
      "Epoch 772/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7942 - val_loss: 99.5243\n",
      "Epoch 773/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.5119 - val_loss: 100.4528\n",
      "Epoch 774/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.0340 - val_loss: 99.0788\n",
      "Epoch 775/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.5046 - val_loss: 98.5827\n",
      "Epoch 776/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6624 - val_loss: 99.4749\n",
      "Epoch 777/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.4769 - val_loss: 98.3025\n",
      "Epoch 778/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6470 - val_loss: 98.9838\n",
      "Epoch 779/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9187 - val_loss: 98.9997\n",
      "Epoch 780/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.4143 - val_loss: 98.2056\n",
      "Epoch 781/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 112.9902 - val_loss: 98.2604\n",
      "Epoch 782/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.4977 - val_loss: 98.6019\n",
      "Epoch 783/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.7838 - val_loss: 100.5562\n",
      "Epoch 784/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7768 - val_loss: 98.7380\n",
      "Epoch 785/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.9128 - val_loss: 99.3633\n",
      "Epoch 786/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6916 - val_loss: 99.0238\n",
      "Epoch 787/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9106 - val_loss: 98.7218\n",
      "Epoch 788/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.7767 - val_loss: 98.8105\n",
      "Epoch 789/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.8127 - val_loss: 99.3648\n",
      "Epoch 790/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.4309 - val_loss: 98.6504\n",
      "Epoch 791/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6460 - val_loss: 99.4983\n",
      "Epoch 792/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5885 - val_loss: 98.8501\n",
      "Epoch 793/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6519 - val_loss: 99.3365\n",
      "Epoch 794/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 113.3845 - val_loss: 98.8115\n",
      "Epoch 795/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.1134 - val_loss: 98.0064\n",
      "Epoch 796/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.0536 - val_loss: 98.1553\n",
      "Epoch 797/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.9662 - val_loss: 98.6720\n",
      "Epoch 798/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.9962 - val_loss: 98.4932\n",
      "Epoch 799/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9111 - val_loss: 99.1766\n",
      "Epoch 800/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6001 - val_loss: 98.8600\n",
      "Epoch 801/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.9794 - val_loss: 98.2399\n",
      "Epoch 802/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6579 - val_loss: 99.0455\n",
      "Epoch 803/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5500 - val_loss: 98.2575\n",
      "Epoch 804/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0481 - val_loss: 98.4884\n",
      "Epoch 805/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9037 - val_loss: 98.4727\n",
      "Epoch 806/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6392 - val_loss: 98.3826\n",
      "Epoch 807/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 112.4726 - val_loss: 98.4808\n",
      "Epoch 808/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6935 - val_loss: 99.0250\n",
      "Epoch 809/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.4539 - val_loss: 98.3749\n",
      "Epoch 810/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 112.9329 - val_loss: 98.1993\n",
      "Epoch 811/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.7604 - val_loss: 100.8983\n",
      "Epoch 812/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.7835 - val_loss: 98.2306\n",
      "Epoch 813/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0195 - val_loss: 98.1757\n",
      "Epoch 814/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 113.2634 - val_loss: 98.4729\n",
      "Epoch 815/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8723 - val_loss: 98.1439\n",
      "Epoch 816/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.8572 - val_loss: 100.5666\n",
      "Epoch 817/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6773 - val_loss: 98.0331\n",
      "Epoch 818/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.5028 - val_loss: 98.7280\n",
      "Epoch 819/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0826 - val_loss: 98.3481\n",
      "Epoch 820/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.9689 - val_loss: 99.5630\n",
      "Epoch 821/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9786 - val_loss: 99.1649\n",
      "Epoch 822/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.9883 - val_loss: 99.5731\n",
      "Epoch 823/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.7919 - val_loss: 98.5613\n",
      "Epoch 824/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.7548 - val_loss: 98.1511\n",
      "Epoch 825/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6840 - val_loss: 98.8340\n",
      "Epoch 826/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8469 - val_loss: 98.4078\n",
      "Epoch 827/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6958 - val_loss: 99.1896\n",
      "Epoch 828/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.5470 - val_loss: 98.8602\n",
      "Epoch 829/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.3703 - val_loss: 99.4562\n",
      "Epoch 830/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.5152 - val_loss: 99.4613\n",
      "Epoch 831/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8481 - val_loss: 98.8238\n",
      "Epoch 832/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7372 - val_loss: 97.9654\n",
      "Epoch 833/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 112.8007 - val_loss: 98.7248\n",
      "Epoch 834/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.4178 - val_loss: 98.5707\n",
      "Epoch 835/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5623 - val_loss: 98.9838\n",
      "Epoch 836/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7217 - val_loss: 99.2867\n",
      "Epoch 837/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6962 - val_loss: 98.9079\n",
      "Epoch 838/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.4837 - val_loss: 98.6074\n",
      "Epoch 839/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.5182 - val_loss: 98.6412\n",
      "Epoch 840/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5769 - val_loss: 98.3265\n",
      "Epoch 841/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.8361 - val_loss: 98.5164\n",
      "Epoch 842/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.9105 - val_loss: 98.4410\n",
      "Epoch 843/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.4123 - val_loss: 99.6363\n",
      "Epoch 844/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9128 - val_loss: 99.3374\n",
      "Epoch 845/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6182 - val_loss: 98.4251\n",
      "Epoch 846/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 112.5984 - val_loss: 99.1465\n",
      "Epoch 847/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5569 - val_loss: 98.4475\n",
      "Epoch 848/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6961 - val_loss: 98.6302\n",
      "Epoch 849/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.4888 - val_loss: 98.3919\n",
      "Epoch 850/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.7013 - val_loss: 99.1450\n",
      "Epoch 851/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.8166 - val_loss: 98.5272\n",
      "Epoch 852/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.0679 - val_loss: 98.6051\n",
      "Epoch 853/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.8140 - val_loss: 99.7764\n",
      "Epoch 854/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.3218 - val_loss: 98.0097\n",
      "Epoch 855/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.2725 - val_loss: 99.3558\n",
      "Epoch 856/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5054 - val_loss: 98.3000\n",
      "Epoch 857/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 112.6781 - val_loss: 98.8088\n",
      "Epoch 858/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.7910 - val_loss: 99.4102\n",
      "Epoch 859/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.1848 - val_loss: 98.1977\n",
      "Epoch 860/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 114.0973 - val_loss: 99.6033\n",
      "Epoch 861/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6914 - val_loss: 98.0478\n",
      "Epoch 862/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.3455 - val_loss: 99.3402\n",
      "Epoch 863/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.7057 - val_loss: 98.3696\n",
      "Epoch 864/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.4410 - val_loss: 98.5291\n",
      "Epoch 865/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.5937 - val_loss: 98.7150\n",
      "Epoch 866/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8362 - val_loss: 98.3416\n",
      "Epoch 867/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6613 - val_loss: 99.0260\n",
      "Epoch 868/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 112.9155 - val_loss: 99.5196\n",
      "Epoch 869/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6900 - val_loss: 98.4424\n",
      "Epoch 870/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7468 - val_loss: 98.9194\n",
      "Epoch 871/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6605 - val_loss: 98.3081\n",
      "Epoch 872/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9819 - val_loss: 98.2123\n",
      "Epoch 873/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6179 - val_loss: 99.7430\n",
      "Epoch 874/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.4560 - val_loss: 98.3817\n",
      "Epoch 875/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6666 - val_loss: 98.4407\n",
      "Epoch 876/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8452 - val_loss: 98.0263\n",
      "Epoch 877/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.1722 - val_loss: 99.3658\n",
      "Epoch 878/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.2642 - val_loss: 98.0662\n",
      "Epoch 879/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 113.1174 - val_loss: 98.2769\n",
      "Epoch 880/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.2813 - val_loss: 99.1143\n",
      "Epoch 881/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6518 - val_loss: 98.8058\n",
      "Epoch 882/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.4184 - val_loss: 98.7348\n",
      "Epoch 883/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7152 - val_loss: 99.8937\n",
      "Epoch 884/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5663 - val_loss: 98.1979\n",
      "Epoch 885/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0685 - val_loss: 100.6734\n",
      "Epoch 886/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.5533 - val_loss: 98.0472\n",
      "Epoch 887/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7083 - val_loss: 98.5764\n",
      "Epoch 888/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.9575 - val_loss: 98.0039\n",
      "Epoch 889/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.5791 - val_loss: 99.3183\n",
      "Epoch 890/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.8705 - val_loss: 98.1622\n",
      "Epoch 891/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.6319 - val_loss: 98.5367\n",
      "Epoch 892/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6192 - val_loss: 98.8790\n",
      "Epoch 893/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8624 - val_loss: 99.8107\n",
      "Epoch 894/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.6740 - val_loss: 98.7069\n",
      "Epoch 895/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8508 - val_loss: 99.8872\n",
      "Epoch 896/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.3133 - val_loss: 98.7880\n",
      "Epoch 897/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.1156 - val_loss: 99.1264\n",
      "Epoch 898/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5744 - val_loss: 98.0270\n",
      "Epoch 899/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.7434 - val_loss: 100.1552\n",
      "Epoch 900/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5931 - val_loss: 98.3343\n",
      "Epoch 901/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.4371 - val_loss: 98.1285\n",
      "Epoch 902/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.6408 - val_loss: 100.5587\n",
      "Epoch 903/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.1197 - val_loss: 99.0403\n",
      "Epoch 904/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.1066 - val_loss: 98.2684\n",
      "Epoch 905/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.0729 - val_loss: 100.4803\n",
      "Epoch 906/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6176 - val_loss: 98.2297\n",
      "Epoch 907/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.9246 - val_loss: 98.7676\n",
      "Epoch 908/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6537 - val_loss: 98.5416\n",
      "Epoch 909/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.3295 - val_loss: 99.0859\n",
      "Epoch 910/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6756 - val_loss: 98.5407\n",
      "Epoch 911/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.3683 - val_loss: 99.5243\n",
      "Epoch 912/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8120 - val_loss: 97.9201\n",
      "Epoch 913/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0756 - val_loss: 99.1312\n",
      "Epoch 914/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 112.9949 - val_loss: 98.4020\n",
      "Epoch 915/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0840 - val_loss: 98.4053\n",
      "Epoch 916/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.7980 - val_loss: 98.9347\n",
      "Epoch 917/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.4636 - val_loss: 100.1359\n",
      "Epoch 918/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0368 - val_loss: 98.9136\n",
      "Epoch 919/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 112.6389 - val_loss: 98.4342\n",
      "Epoch 920/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.4181 - val_loss: 98.2803\n",
      "Epoch 921/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 112.4728 - val_loss: 99.0266\n",
      "Epoch 922/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8673 - val_loss: 97.9810\n",
      "Epoch 923/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.2144 - val_loss: 98.1647\n",
      "Epoch 924/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7055 - val_loss: 98.9478\n",
      "Epoch 925/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7252 - val_loss: 98.9464\n",
      "Epoch 926/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 113.2719 - val_loss: 98.4322\n",
      "Epoch 927/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.7397 - val_loss: 98.8011\n",
      "Epoch 928/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8187 - val_loss: 98.2159\n",
      "Epoch 929/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5884 - val_loss: 98.4448\n",
      "Epoch 930/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5833 - val_loss: 99.0101\n",
      "Epoch 931/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6072 - val_loss: 99.0443\n",
      "Epoch 932/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7616 - val_loss: 98.1829\n",
      "Epoch 933/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.9321 - val_loss: 99.8995\n",
      "Epoch 934/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5739 - val_loss: 98.3857\n",
      "Epoch 935/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0537 - val_loss: 98.7737\n",
      "Epoch 936/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 114.1556 - val_loss: 100.8550\n",
      "Epoch 937/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 114.4591 - val_loss: 98.0376\n",
      "Epoch 938/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 112.5538 - val_loss: 99.4065\n",
      "Epoch 939/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7626 - val_loss: 99.1007\n",
      "Epoch 940/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.5868 - val_loss: 98.1947\n",
      "Epoch 941/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6668 - val_loss: 99.6062\n",
      "Epoch 942/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 115.1595 - val_loss: 100.0370\n",
      "Epoch 943/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 114.0721 - val_loss: 98.0099\n",
      "Epoch 944/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.8468 - val_loss: 99.4730\n",
      "Epoch 945/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 113.1667 - val_loss: 98.0421\n",
      "Epoch 946/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.9943 - val_loss: 98.8961\n",
      "Epoch 947/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 114.5681 - val_loss: 100.7722\n",
      "Epoch 948/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5616 - val_loss: 97.9418\n",
      "Epoch 949/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 113.0109 - val_loss: 98.4593\n",
      "Epoch 950/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.4387 - val_loss: 98.4525\n",
      "Epoch 951/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6554 - val_loss: 98.1290\n",
      "Epoch 952/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0455 - val_loss: 98.3677\n",
      "Epoch 953/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.8829 - val_loss: 98.2038\n",
      "Epoch 954/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.4938 - val_loss: 98.6937\n",
      "Epoch 955/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.6061 - val_loss: 98.4167\n",
      "Epoch 956/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7235 - val_loss: 98.5223\n",
      "Epoch 957/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0410 - val_loss: 98.5071\n",
      "Epoch 958/1000\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 112.8107 - val_loss: 98.6799\n",
      "Epoch 959/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.5528 - val_loss: 98.6636\n",
      "Epoch 960/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 114.1948 - val_loss: 100.0479\n",
      "Epoch 961/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.6890 - val_loss: 98.2836\n",
      "Epoch 962/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 112.4433 - val_loss: 99.1880\n",
      "Epoch 963/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.7063 - val_loss: 98.9152\n",
      "Epoch 964/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 112.7291 - val_loss: 98.1353\n",
      "Epoch 965/1000\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 112.5067 - val_loss: 99.1886\n",
      "Epoch 966/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 112.5208 - val_loss: 98.3742\n",
      "Epoch 967/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.4690 - val_loss: 98.9759\n",
      "Epoch 968/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6575 - val_loss: 98.7042\n",
      "Epoch 969/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 113.2775 - val_loss: 98.1263\n",
      "Epoch 970/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 113.1509 - val_loss: 99.3996\n",
      "Epoch 971/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.5587 - val_loss: 98.8906\n",
      "Epoch 972/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.7057 - val_loss: 98.2696\n",
      "Epoch 973/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 113.1285 - val_loss: 99.0597\n",
      "Epoch 974/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 112.8732 - val_loss: 98.0928\n",
      "Epoch 975/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 114.4595 - val_loss: 100.6680\n",
      "Epoch 976/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 113.0719 - val_loss: 97.9839\n",
      "Epoch 977/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.2125 - val_loss: 98.3885\n",
      "Epoch 978/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 113.3043 - val_loss: 99.7420\n",
      "Epoch 979/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 112.7113 - val_loss: 98.8122\n",
      "Epoch 980/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.4795 - val_loss: 98.2310\n",
      "Epoch 981/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.6572 - val_loss: 98.6467\n",
      "Epoch 982/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 113.2312 - val_loss: 100.1521\n",
      "Epoch 983/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.9015 - val_loss: 98.5756\n",
      "Epoch 984/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.0131 - val_loss: 99.0263\n",
      "Epoch 985/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.8917 - val_loss: 99.0520\n",
      "Epoch 986/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 113.0569 - val_loss: 100.7094\n",
      "Epoch 987/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 112.8659 - val_loss: 98.0714\n",
      "Epoch 988/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 113.4142 - val_loss: 98.7007\n",
      "Epoch 989/1000\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 113.8461 - val_loss: 100.4616\n",
      "Epoch 990/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 114.5776 - val_loss: 98.1111\n",
      "Epoch 991/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 112.5332 - val_loss: 99.1278\n",
      "Epoch 992/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 113.0179 - val_loss: 98.4375\n",
      "Epoch 993/1000\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 112.5642 - val_loss: 98.8392\n",
      "Epoch 994/1000\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 112.7260 - val_loss: 99.6453\n",
      "Epoch 995/1000\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 112.8926 - val_loss: 98.6789\n",
      "Epoch 996/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.4112 - val_loss: 99.0739\n",
      "Epoch 997/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.6676 - val_loss: 98.5799\n",
      "Epoch 998/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 112.4005 - val_loss: 98.5444\n",
      "Epoch 999/1000\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 113.2926 - val_loss: 100.0382\n",
      "Epoch 1000/1000\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 113.6569 - val_loss: 98.0678\n"
     ]
    }
   ],
   "source": [
    "neuralnet_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# TensorBoard callback\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "history = neuralnet_model.fit(X_Train, Y_Train, epochs=1000, validation_data=(X_Test, Y_Test), \n",
    "                    verbose=1, callbacks=[tensorboard_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot training & validation loss values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Squared Error on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 991us/step - loss: 98.0678\n",
      "Mean Squared Error on Test Data: 98.06780242919922\n"
     ]
    }
   ],
   "source": [
    "test_loss = neuralnet_model.evaluate(X_Test, Y_Test, verbose=1)\n",
    "\n",
    "print(f\"Mean Squared Error on Test Data: {test_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save The Final Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralnet_model.save_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local The Final Model Weights from Saved `.h5` File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new instance of the same model\n",
    "new_model = NeuralNetwork()\n",
    "\n",
    "# Call the model on some data (this could be a batch of your actual data or dummy data)\n",
    "dummy_data = tf.zeros((1, 8))  # Assuming the input shape is (None, 8)\n",
    "new_model(dummy_data)\n",
    "\n",
    "# Load the previously saved weights\n",
    "new_model.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the entire model to the TensorFlow SavedModel format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mymodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mymodel/assets\n"
     ]
    }
   ],
   "source": [
    "neuralnet_model.save('mymodel', save_format='tf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the entire model from the TensorFlow SavedModel format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('mymodel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamkernel",
   "language": "python",
   "name": "streamkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
