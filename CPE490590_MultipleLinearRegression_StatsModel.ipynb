{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression using Statsmodel\n",
    "## CPE 490 590 \n",
    "### Author: Rahul Bhadani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas!=2.1.0,>=1.0 in /home/infinitive/.local/lib/python3.10/site-packages (from statsmodels) (1.5.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /home/infinitive/anaconda3/envs/stream/lib/python3.10/site-packages (from statsmodels) (1.12.0)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/patsy/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting patsy>=0.5.4\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.9/233.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2,>=1.18 in /home/infinitive/anaconda3/envs/stream/lib/python3.10/site-packages (from statsmodels) (1.24.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/infinitive/anaconda3/envs/stream/lib/python3.10/site-packages (from statsmodels) (23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/infinitive/anaconda3/envs/stream/lib/python3.10/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/infinitive/anaconda3/envs/stream/lib/python3.10/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2022.7.1)\n",
      "Requirement already satisfied: six in /home/infinitive/anaconda3/envs/stream/lib/python3.10/site-packages (from patsy>=0.5.4->statsmodels) (1.16.0)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-0.5.6 statsmodels-0.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The multiple linear regression used in this notebook, doesn'thave bias term $w_0$, i.e. $w_0 = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm \n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Serif'\n",
    "plt.rcParams['font.size'] = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TV', 'Radio', 'Newspaper', 'Sales'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Dataset/Advertising/Advertising.csv', index_col=0)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains TV Budget, Radio Budget and Newspaper Budget for an advertisement of a product at a company and Sales.\n",
    "\n",
    "Our goal is to predict sales based on TV Budget, Radio Budget and Newspaper Budget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Dataset into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[['TV', 'Radio', 'Newspaper']]\n",
    "y = df[['Sales']]\n",
    "# Separate features and labels\n",
    "x = df_filtered.values.astype(np.float64)\n",
    "y = y.values.reshape(-1, 1).astype(np.float64)\n",
    "\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(x, y, test_size = 1/3, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Simple Linear Regression to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = sm.add_constant(X_Train) \n",
    "est = sm.OLS(Y_Train, xt).fit() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the Summary of the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.907</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.905</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   418.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 20 Feb 2024</td> <th>  Prob (F-statistic):</th> <td>3.02e-66</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:18:18</td>     <th>  Log-Likelihood:    </th> <td> -250.83</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   133</td>      <th>  AIC:               </th> <td>   509.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   129</td>      <th>  BIC:               </th> <td>   521.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    2.9038</td> <td>    0.368</td> <td>    7.886</td> <td> 0.000</td> <td>    2.175</td> <td>    3.632</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0443</td> <td>    0.002</td> <td>   26.445</td> <td> 0.000</td> <td>    0.041</td> <td>    0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.1966</td> <td>    0.010</td> <td>   20.420</td> <td> 0.000</td> <td>    0.178</td> <td>    0.216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0026</td> <td>    0.007</td> <td>    0.371</td> <td> 0.712</td> <td>   -0.011</td> <td>    0.017</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>10.854</td> <th>  Durbin-Watson:     </th> <td>   2.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.004</td> <th>  Jarque-Bera (JB):  </th> <td>  11.895</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.731</td> <th>  Prob(JB):          </th> <td> 0.00261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.909</td> <th>  Cond. No.          </th> <td>    462.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.907   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.905   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     418.1   \\\\\n",
       "\\textbf{Date:}             & Tue, 20 Feb 2024 & \\textbf{  Prob (F-statistic):} &  3.02e-66   \\\\\n",
       "\\textbf{Time:}             &     16:18:18     & \\textbf{  Log-Likelihood:    } &   -250.83   \\\\\n",
       "\\textbf{No. Observations:} &         133      & \\textbf{  AIC:               } &     509.7   \\\\\n",
       "\\textbf{Df Residuals:}     &         129      & \\textbf{  BIC:               } &     521.2   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       2.9038  &        0.368     &     7.886  &         0.000        &        2.175    &        3.632     \\\\\n",
       "\\textbf{x1}    &       0.0443  &        0.002     &    26.445  &         0.000        &        0.041    &        0.048     \\\\\n",
       "\\textbf{x2}    &       0.1966  &        0.010     &    20.420  &         0.000        &        0.178    &        0.216     \\\\\n",
       "\\textbf{x3}    &       0.0026  &        0.007     &     0.371  &         0.712        &       -0.011    &        0.017     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 10.854 & \\textbf{  Durbin-Watson:     } &    2.117  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.004 & \\textbf{  Jarque-Bera (JB):  } &   11.895  \\\\\n",
       "\\textbf{Skew:}          & -0.731 & \\textbf{  Prob(JB):          } &  0.00261  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.909 & \\textbf{  Cond. No.          } &     462.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.907\n",
       "Model:                            OLS   Adj. R-squared:                  0.905\n",
       "Method:                 Least Squares   F-statistic:                     418.1\n",
       "Date:                Tue, 20 Feb 2024   Prob (F-statistic):           3.02e-66\n",
       "Time:                        16:18:18   Log-Likelihood:                -250.83\n",
       "No. Observations:                 133   AIC:                             509.7\n",
       "Df Residuals:                     129   BIC:                             521.2\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          2.9038      0.368      7.886      0.000       2.175       3.632\n",
       "x1             0.0443      0.002     26.445      0.000       0.041       0.048\n",
       "x2             0.1966      0.010     20.420      0.000       0.178       0.216\n",
       "x3             0.0026      0.007      0.371      0.712      -0.011       0.017\n",
       "==============================================================================\n",
       "Omnibus:                       10.854   Durbin-Watson:                   2.117\n",
       "Prob(Omnibus):                  0.004   Jarque-Bera (JB):               11.895\n",
       "Skew:                          -0.731   Prob(JB):                      0.00261\n",
       "Kurtosis:                       2.909   Cond. No.                         462.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "In the above result, we see that $R^2$ coefficient of determination was $0.907$,and estimated coefficients were $w_0 = 2.9038$, $w_1 = 0.0443\t$, $w_2 = 0.1966$, and $w_3 = 0.0026$.\n",
    "We can also see their respective 95% confidence interval as [2.175,\t3.632], [0.041,\t0.048], [0.178,\t0.216], and [-0.011,\t0.017].\n",
    "\n",
    "Note: the answer might be different if rerun the notebook and training and test split will happen randomly everytime the whole notebook is run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = sm.add_constant(X_Test)\n",
    "\n",
    "# Make a prediction\n",
    "y_pred = est.predict(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3864786054959777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Calculate the Mean Squared Error\n",
    "mse = mean_squared_error(Y_Test, y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamkernel",
   "language": "python",
   "name": "streamkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
